{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo5_yolo2_prune_retraining_colab-feature/Tomas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "heading_collapsed": true,
        "id": "DloS7VJTgg8i"
      },
      "source": [
        "# Start - Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "tIIpnxPngg8n",
        "outputId": "3f4ce53a-d93a-4243-97cc-0ba3a59a6517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Step1 - Get repo\n",
        "! rm -rf CS4180-DL\n",
        "! git clone https://github.com/prerakmody/CS4180-DL\n",
        "\n",
        "# Step2 - Get Dataset\n",
        "! wget -P /content/CS4180-DL/data/dataset https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
        "! tar xf /content/CS4180-DL/data/dataset/VOCtrainval_11-May-2012.tar --directory /content/CS4180-DL/data/dataset\n",
        "! wget -P /content/CS4180-DL/data/dataset https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
        "! tar xf /content/CS4180-DL/data/dataset/VOCtrainval_06-Nov-2007.tar --directory /content/CS4180-DL/data/dataset\n",
        "! wget -P /content/CS4180-DL/data/dataset https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
        "! tar xf /content/CS4180-DL/data/dataset/VOCtest_06-Nov-2007.tar --directory /content/CS4180-DL/data/dataset\n",
        "! mkdir /content/CS4180-DL/data/weights\n",
        "\n",
        "! wget -P /content/CS4180-DL/data/weights https://pjreddie.com/media/files/yolov2-voc.weights"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS4180-DL'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 21861 (delta 192), reused 185 (delta 91), pack-reused 21569\u001b[K\n",
            "Receiving objects: 100% (21861/21861), 839.58 MiB | 39.43 MiB/s, done.\n",
            "Resolving deltas: 100% (10252/10252), done.\n",
            "--2019-06-14 14:44:10--  https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1999639040 (1.9G) [application/octet-stream]\n",
            "Saving to: ‘/content/CS4180-DL/data/dataset/VOCtrainval_11-May-2012.tar’\n",
            "\n",
            "VOCtrainval_11-May- 100%[===================>]   1.86G  4.49MB/s    in 24m 24s \n",
            "\n",
            "2019-06-14 15:08:35 (1.30 MB/s) - ‘/content/CS4180-DL/data/dataset/VOCtrainval_11-May-2012.tar’ saved [1999639040/1999639040]\n",
            "\n",
            "--2019-06-14 15:09:09--  https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/octet-stream]\n",
            "Saving to: ‘/content/CS4180-DL/data/dataset/VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  2.43MB/s    in 6m 31s  \n",
            "\n",
            "2019-06-14 15:15:40 (1.12 MB/s) - ‘/content/CS4180-DL/data/dataset/VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n",
            "--2019-06-14 15:16:05--  https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/octet-stream]\n",
            "Saving to: ‘/content/CS4180-DL/data/dataset/VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M   830KB/s    in 4m 13s  \n",
            "\n",
            "2019-06-14 15:20:18 (1.70 MB/s) - ‘/content/CS4180-DL/data/dataset/VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
            "\n",
            "--2019-06-14 15:20:58--  https://pjreddie.com/media/files/yolov2-voc.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202704264 (193M) [application/octet-stream]\n",
            "Saving to: ‘/content/CS4180-DL/data/weights/yolov2-voc.weights’\n",
            "\n",
            "yolov2-voc.weights  100%[===================>] 193.31M  2.97MB/s    in 2m 45s  \n",
            "\n",
            "2019-06-14 15:23:43 (1.18 MB/s) - ‘/content/CS4180-DL/data/weights/yolov2-voc.weights’ saved [202704264/202704264]\n",
            "\n",
            "CPU times: user 22.5 s, sys: 5.32 s, total: 27.9 s\n",
            "Wall time: 40min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-28T09:28:23.399092Z",
          "start_time": "2019-05-28T09:28:18.026766Z"
        },
        "colab_type": "code",
        "hidden": true,
        "id": "L677712ngg8z",
        "outputId": "511c9f8b-a300-4568-ecea-71a09edc1c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "## Step3 - Add path to main dir\n",
        "DIR_MAIN = os.path.abspath('CS4180-DL/') #'../../../CS4180-DL/'\n",
        "sys.path.append(DIR_MAIN)\n",
        "\n",
        "## Step4 - Download pruned weights from GDrive\n",
        "from src.utils import download_gdrive\n",
        "# FILE_ID =  '1dHnUQ8G3GObZSMh9eQ0zUR5wor0ttW3U' # weight-pruning\n",
        "# FILE_ID = '1I9FE3X5luVTQ0p9j8g1RWy63t5NiRWw_' # filter-pruning\n",
        "# DIR_WEIGHTS = os.path.join(DIR_MAIN, 'data/weights/pruned')\n",
        "# ! mkdir {DIR_WEIGHTS}\n",
        "# DEST_NAME_ZIP   = os.path.join(DIR_WEIGHTS, 'weights-prune-me.zip')\n",
        "# DEST_NAME_FILES = DIR_WEIGHTS\n",
        "# download_gdrive(FILE_ID, DEST_NAME_ZIP)\n",
        "# ! unzip {DEST_NAME_ZIP} -d {DEST_NAME_FILES}\n",
        "\n",
        "## Step5 - Generate .txt files for training/validation \n",
        "from src.dataloader import setup_VOC\n",
        "DIR_DATA = os.path.join(DIR_MAIN, 'data/dataset/')\n",
        "setup_VOC(DIR_DATA)\n",
        "DIR_DATA_VOC = os.path.join(DIR_DATA, 'VOCdevkit')\n",
        "! cat {DIR_DATA_VOC}/2007_train.txt {DIR_DATA_VOC}/2007_val.txt {DIR_DATA_VOC}/2012_*.txt > {DIR_DATA_VOC}/voc_train.txt\n",
        "\n",
        "## Step6 - Check which GPU\n",
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - year :  2012  || image_set :  train\n",
            " - year :  2012  || image_set :  val\n",
            " - year :  2007  || image_set :  train\n",
            " - year :  2007  || image_set :  val\n",
            " - year :  2007  || image_set :  test\n",
            "Fri Jun 14 15:24:17 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "oHfKJbbogg9B"
      },
      "source": [
        "# Start - Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "x11xh5u4gg9E",
        "outputId": "7983ff4b-45ed-4840-b423-e552fc33fee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "\n",
        "dir_main = os.path.abspath('CS4180-DL')\n",
        "sys.path.append(dir_main)\n",
        "print (' - In Path : ', sys.path[-1])\n",
        "\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "print (' - USE_GPU : ', USE_GPU)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - In Path :  /content/CS4180-DL\n",
            " - USE_GPU :  True\n",
            "Fri Jun 14 15:24:32 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    32W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "NRjbMQVrgg9K"
      },
      "source": [
        "# Start - Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "hidden": true,
        "id": "Tr1x-adxgg9M",
        "outputId": "c46aa82b-673d-4ee7-fde2-778c29412337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "from src.predict import *\n",
        "from src.nets import *\n",
        "\n",
        "from src.pruning.weightPruning.methods import weight_prune,quick_filter_prune\n",
        "from src.pruning.weightPruning.utils import prune_rate\n",
        "\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "\n",
        "if (1):\n",
        "    DIR_PROJ         = 'CS4180-DL'\n",
        "\n",
        "if (1):\n",
        "    MODEL            = ''\n",
        "    MODEL_CFGFILE    = os.path.join(DIR_PROJ, 'data/cfg/github_pjreddie/yolov2-voc.cfg')\n",
        "    \n",
        "    MODEL_WEIGHTFILE = os.path.join(DIR_PROJ, 'data/weights/yolov2-voc.weights') #['0.5' : 0.6366, '0.25' : 0.7, '0.1' : 0.7363]\n",
        "    EVAL_PREFIX      = 'iter1_pretrained_'\n",
        "    \n",
        "    MODEL_LOSS       = RegionLoss()\n",
        "    \n",
        "    PASCAL_DIR       = os.path.join(DIR_PROJ, 'data/dataset/VOCdevkit/')\n",
        "    EVAL_IMAGELIST   = os.path.join(DIR_PROJ, 'data/dataset/VOCdevkit/2007_test.txt')\n",
        "    EVAL_OUTPUTDIR   = os.path.join(DIR_PROJ, 'eval_data')\n",
        "    EVAL_OUTPUTDIR_PKL = os.path.join(DIR_PROJ, 'eval_results')\n",
        "\n",
        "    \n",
        "    print (' - 0. MODEL       : ', MODEL)\n",
        "    print (' - 0. MODEL_WEIGHT: ', MODEL_WEIGHTFILE)\n",
        "    print (' - 0. EVAL_PREFIX : ', EVAL_PREFIX)\n",
        "    \n",
        "if (1):\n",
        "    BATCH_SIZE = 32\n",
        "    CONF_THRESH = 0.05 # [0.5, 0.25, 0.1, 0.005]\n",
        "    print (' - 0. BATCH_SIZE  : ', BATCH_SIZE)\n",
        "    print (' - 0. CONF_THRESH : ', CONF_THRESH)\n",
        "    \n",
        "if (1):\n",
        "    try:\n",
        "        print (' - 0. Logger      : ', LOGGER)\n",
        "    except:\n",
        "        LOGGER = TensorBoardColab()\n",
        "        print (' - 0. Logger      : ', LOGGER)    \n",
        "    \n",
        "    print ('')\n",
        "\n",
        "\n",
        "valObj = PASCALVOCEval(MODEL, MODEL_CFGFILE, MODEL_WEIGHTFILE, MODEL_LOSS \n",
        "                       ,PASCAL_DIR, EVAL_IMAGELIST, EVAL_OUTPUTDIR, EVAL_PREFIX, EVAL_OUTPUTDIR_PKL\n",
        "                       , LOGGER)\n",
        "valObj.predict(BATCH_SIZE=BATCH_SIZE, CONF_THRESH=CONF_THRESH)\n",
        "# valObj._do_python_eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " - 0. MODEL       :  \n",
            " - 0. MODEL_WEIGHT:  CS4180-DL/data/weights/yolov2-voc.weights\n",
            " - 0. EVAL_PREFIX :  iter1_pretrained_\n",
            " - 0. BATCH_SIZE  :  32\n",
            " - 0. CONF_THRESH :  0.05\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://441f3086.ngrok.io\n",
            " - 0. Logger      :  <tensorboardcolab.core.TensorBoardColab object at 0x7fa981349a20>\n",
            "\n",
            " - 1. Loading model :  CS4180-DL/data/weights/yolov2-voc.weights\n",
            "  -- [DEBUG] Non-BN Block :  {'type': 'convolutional', 'batch_normalize': 0, 'size': '1', 'stride': '1', 'pad': '1', 'filters': '125', 'activation': 'linear'}\n",
            "  -- [DEBUG][Darknet] self.anchors :  [1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071]\n",
            "  -- [DEBUG][Darknet] self.num_anchors :  5\n",
            "  -- [DEBUG][Darknet] self.anchor_step :  2.0\n",
            "  -- [DEBUG][Darknet] self.num_classes :  20\n",
            "  -- [DEBUG][Darknet] self.loss :  RegionLoss()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0eab123e94b40aa892f034dc3e092a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=4960), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0614 15:29:47.181011 140368128042880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0614 15:29:47.193191 140368128042880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:101: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  -- Reading predictions from :  CS4180-DL/eval_data / iter1_pretrained_ *\n",
            "Mean AP = 0.7429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "Gslf5Jiqgg9Q"
      },
      "source": [
        "# Start - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          11,
          17,
          26,
          36,
          40,
          72
        ],
        "hidden": true,
        "id": "nIzgURFiqzYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reset\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "    \n",
        "    if (1):\n",
        "        DIR_MAIN         = os.path.abspath('CS4180-DL')\n",
        "        sys.path.append(DIR_MAIN)\n",
        "        print (' - 0. DIR_MAIN     :  ', DIR_MAIN)\n",
        "        from src.train import YOLOv2Train\n",
        "        \n",
        "    if (1):\n",
        "        PASCAL_DIR   = os.path.join(DIR_MAIN, 'data/dataset/VOCdevkit/')\n",
        "        PASCAL_TRAIN = os.path.join(DIR_MAIN, 'data/dataset/VOCdevkit/voc_train.txt')\n",
        "        PASCAL_VALID = os.path.join(DIR_MAIN, 'data/dataset/VOCdevkit/2007_test.txt')\n",
        "        TRAIN_LOGDIR = os.path.join(DIR_MAIN, 'train_data')\n",
        "        VAL_LOGDIR   = os.path.join(DIR_MAIN, 'eval_data')\n",
        "        VAL_OUTPUTDIR_PKL = os.path.join(DIR_MAIN, 'eval_results')\n",
        "        MODEL_CFG    = os.path.join(DIR_MAIN, 'data/cfg/github_pjreddie/yolov2-voc.cfg')\n",
        "        \n",
        "    if (1):\n",
        "        \n",
        "        MODEL_WEIGHT = os.path.join(DIR_MAIN, 'data/weights/yolov2-voc.weights')\n",
        "        VAL_PREFIX   = 'pretrained_'\n",
        "        \n",
        "        print (' - 0. MODEL_WEIGHT :  ', MODEL_WEIGHT)\n",
        "        print (' - 0. VAL_PREFIX   : ', VAL_PREFIX)\n",
        "        \n",
        "    if (1):\n",
        "        BATCH_SIZE    = 32;\n",
        "        print (' - 0. BATCH_SIZE    : ', BATCH_SIZE)\n",
        "        \n",
        "    if (1):\n",
        "        DEBUG_EPOCHS = -1 #[-1, 50]\n",
        "        MAX_EPOCHS   = 100\n",
        "        \n",
        "        print (' - 0. DEBUG_EPOCHS : ', DEBUG_EPOCHS)\n",
        "        print (' - 0. MAX_EPOCHS   : ', MAX_EPOCHS)\n",
        "\n",
        "    if (1):\n",
        "        LEARNING_RATE = 0.00025\n",
        "        print (' - 0. LEARNING_RATE : ', LEARNING_RATE)\n",
        "        LEARNING_RATES = [LEARNING_RATE for _ in range(MAX_EPOCHS)]\n",
        "    else:\n",
        "        import numpy as np\n",
        "        a = np.linspace(0.0005,0.0001, 10)\n",
        "        b = np.linspace(0.0001, 0.00001, 10)\n",
        "        c = np.linspace(0.00001, 0.0001, 10)\n",
        "        d = np.linspace(0.0001, 0.0005,10) \n",
        "        LEARNING_RATES = np.hstack((a,b,c,d,a,b,c,d,a,b))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.plot(LEARNING_RATES)\n",
        "        plt.title('Cyclical Learning Rates')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Learning Rate')\n",
        "        plt.show()\n",
        "    \n",
        "    assert len(LEARNING_RATES) == MAX_EPOCHS\n",
        "    \n",
        "    if (1):\n",
        "        pruning_perc   = 20. #[0, 10., 30., 50., 70., 90.]\n",
        "        pruning_method = \"filter\" # [\"filter\", \"weight\"]\n",
        "    \n",
        "    if (1):\n",
        "        try:\n",
        "            LOGGER = ''\n",
        "            print (' - 0. Logger       : ', LOGGER)\n",
        "        except:\n",
        "            LOGGER = TensorBoardColab()\n",
        "            print (' - 0. Logger       : ', LOGGER)\n",
        "        print ('')\n",
        "    \n",
        "\n",
        "    if (1):\n",
        "        trainObj = YOLOv2Train()\n",
        "        trainObj.train(PASCAL_DIR, PASCAL_TRAIN, PASCAL_VALID, TRAIN_LOGDIR, VAL_LOGDIR, VAL_OUTPUTDIR_PKL, VAL_PREFIX\n",
        "                       , MODEL_CFG, MODEL_WEIGHT\n",
        "                       , BATCH_SIZE, LEARNING_RATES, MAX_EPOCHS\n",
        "                       , LOGGER, DEBUG_EPOCHS=DEBUG_EPOCHS, verbose=0\n",
        "                       , pruning_perc=pruning_perc, pruning_method=pruning_method\n",
        "                      )\n",
        "else:\n",
        "    print (' - GPU Issues!!')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}