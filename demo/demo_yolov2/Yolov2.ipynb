{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOADr6UaKAzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # ! rm -rf CS4180-DL\n",
        "# ! git clone --branch rukai-yolo2 https://github.com/prerakmody/CS4180-DL.git\n",
        "\n",
        "# ! wget https://pjreddie.com/media/files/yolov2-voc.weights\n",
        "# ! git clone https://github.com/marvis/pytorch-yolo2.git\n",
        "\n",
        "# # Get The Pascal VOC Data\n",
        "# ! wget https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
        "# ! wget https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
        "# ! wget https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
        "# ! tar xf VOCtrainval_11-May-2012.tar\n",
        "# ! tar xf VOCtrainval_06-Nov-2007.tar\n",
        "# ! tar xf VOCtest_06-Nov-2007.tar\n",
        "\n",
        "# # Generate Labels for VOC\n",
        "\n",
        "# ! wget http://pjreddie.com/media/files/voc_label.py\n",
        "# ! python voc_label.py\n",
        "# ! cat 2007_train.txt 2007_val.txt 2012_*.txt > voc_train.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCfp4DyNMZNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "6857e4c9-f39e-4016-8f15-455fa7d0d098"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 25 15:13:50 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    15W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9giwV7LMfn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataloader\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "## --------------------------------------- PASCAL VOC - v2 --------------------------------------- ##\n",
        "\n",
        "class VOCDatasetv2(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, shape=None, shuffle=True, transform=None, target_transform=None, train=False, seen=0, batch_size=64, num_workers=4):\n",
        "       with open(root, 'r') as file:\n",
        "           self.lines = file.readlines()\n",
        "\n",
        "       if shuffle:\n",
        "           random.shuffle(self.lines)\n",
        "\n",
        "       self.nSamples  = len(self.lines)\n",
        "       self.transform = transform\n",
        "       self.target_transform = target_transform\n",
        "       self.train = train\n",
        "       self.shape = shape\n",
        "       self.seen = seen\n",
        "       self.batch_size = batch_size\n",
        "       self.num_workers = num_workers\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error'\n",
        "        imgpath = self.lines[index].rstrip()\n",
        "\n",
        "        if self.train and index % 64== 0:\n",
        "            if self.seen < 4000*64:\n",
        "               width = 13*32\n",
        "               self.shape = (width, width)\n",
        "            elif self.seen < 8000*64:\n",
        "               width = (random.randint(0,3) + 13)*32\n",
        "               self.shape = (width, width)\n",
        "            elif self.seen < 12000*64:\n",
        "               width = (random.randint(0,5) + 12)*32\n",
        "               self.shape = (width, width)\n",
        "            elif self.seen < 16000*64:\n",
        "               width = (random.randint(0,7) + 11)*32\n",
        "               self.shape = (width, width)\n",
        "            else: # self.seen < 20000*64:\n",
        "               width = (random.randint(0,9) + 10)*32\n",
        "               self.shape = (width, width)\n",
        "\n",
        "        if self.train:\n",
        "            jitter = 0.2\n",
        "            hue = 0.1\n",
        "            saturation = 1.5 \n",
        "            exposure = 1.5\n",
        "\n",
        "            img, label = load_data_detection(imgpath, self.shape, jitter, hue, saturation, exposure)\n",
        "            label = torch.from_numpy(label)\n",
        "        else:\n",
        "            img = Image.open(imgpath).convert('RGB')\n",
        "            if self.shape:\n",
        "                img = img.resize(self.shape)\n",
        "    \n",
        "            labpath = imgpath.replace('images', 'labels').replace('JPEGImages', 'labels').replace('.jpg', '.txt').replace('.png','.txt')\n",
        "            label = torch.zeros(50*5)\n",
        "            #if os.path.getsize(labpath):\n",
        "            #tmp = torch.from_numpy(np.loadtxt(labpath))\n",
        "            try:\n",
        "                tmp = torch.from_numpy(read_truths_args(labpath, 8.0/img.width).astype('float32'))\n",
        "            except Exception:\n",
        "                tmp = torch.zeros(1,5)\n",
        "            #tmp = torch.from_numpy(read_truths(labpath))\n",
        "            tmp = tmp.view(-1)\n",
        "            tsz = tmp.numel()\n",
        "            #print('labpath = %s , tsz = %d' % (labpath, tsz))\n",
        "            if tsz > 50*5:\n",
        "                label = tmp[0:50*5]\n",
        "            elif tsz > 0:\n",
        "                label[0:tsz] = tmp\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        self.seen = self.seen + self.num_workers\n",
        "        return (img, label)\n",
        "\n",
        "def scale_image_channel(im, c, v):\n",
        "    cs = list(im.split())\n",
        "    cs[c] = cs[c].point(lambda i: i * v)\n",
        "    out = Image.merge(im.mode, tuple(cs))\n",
        "    return out\n",
        "\n",
        "def distort_image(im, hue, sat, val):\n",
        "    im = im.convert('HSV')\n",
        "    cs = list(im.split())\n",
        "    cs[1] = cs[1].point(lambda i: i * sat)\n",
        "    cs[2] = cs[2].point(lambda i: i * val)\n",
        "    \n",
        "    def change_hue(x):\n",
        "        x += hue*255\n",
        "        if x > 255:\n",
        "            x -= 255\n",
        "        if x < 0:\n",
        "            x += 255\n",
        "        return x\n",
        "    cs[0] = cs[0].point(change_hue)\n",
        "    im = Image.merge(im.mode, tuple(cs))\n",
        "\n",
        "    im = im.convert('RGB')\n",
        "    #constrain_image(im)\n",
        "    return im\n",
        "\n",
        "def rand_scale(s):\n",
        "    scale = random.uniform(1, s)\n",
        "    if(random.randint(1,10000)%2): \n",
        "        return scale\n",
        "    return 1./scale\n",
        "\n",
        "def random_distort_image(im, hue, saturation, exposure):\n",
        "    dhue = random.uniform(-hue, hue)\n",
        "    dsat = rand_scale(saturation)\n",
        "    dexp = rand_scale(exposure)\n",
        "    res = distort_image(im, dhue, dsat, dexp)\n",
        "    return res\n",
        "\n",
        "def data_augmentation(img, shape, jitter, hue, saturation, exposure):\n",
        "    oh = img.height  \n",
        "    ow = img.width\n",
        "    \n",
        "    dw =int(ow*jitter)\n",
        "    dh =int(oh*jitter)\n",
        "\n",
        "    pleft  = random.randint(-dw, dw)\n",
        "    pright = random.randint(-dw, dw)\n",
        "    ptop   = random.randint(-dh, dh)\n",
        "    pbot   = random.randint(-dh, dh)\n",
        "\n",
        "    swidth =  ow - pleft - pright\n",
        "    sheight = oh - ptop - pbot\n",
        "\n",
        "    sx = float(swidth)  / ow\n",
        "    sy = float(sheight) / oh\n",
        "    \n",
        "    flip = random.randint(1,10000)%2\n",
        "    cropped = img.crop( (pleft, ptop, pleft + swidth - 1, ptop + sheight - 1))\n",
        "\n",
        "    dx = (float(pleft)/ow)/sx\n",
        "    dy = (float(ptop) /oh)/sy\n",
        "\n",
        "    sized = cropped.resize(shape)\n",
        "\n",
        "    if flip: \n",
        "        sized = sized.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    img = random_distort_image(sized, hue, saturation, exposure)\n",
        "    \n",
        "    return img, flip, dx,dy,sx,sy \n",
        "\n",
        "def fill_truth_detection(labpath, w, h, flip, dx, dy, sx, sy):\n",
        "    max_boxes = 50\n",
        "    label = np.zeros((max_boxes,5))\n",
        "    if os.path.getsize(labpath):\n",
        "        bs = np.loadtxt(labpath)\n",
        "        if bs is None:\n",
        "            return label\n",
        "        bs = np.reshape(bs, (-1, 5))\n",
        "        cc = 0\n",
        "        for i in range(bs.shape[0]):\n",
        "            x1 = bs[i][1] - bs[i][3]/2\n",
        "            y1 = bs[i][2] - bs[i][4]/2\n",
        "            x2 = bs[i][1] + bs[i][3]/2\n",
        "            y2 = bs[i][2] + bs[i][4]/2\n",
        "            \n",
        "            x1 = min(0.999, max(0, x1 * sx - dx)) \n",
        "            y1 = min(0.999, max(0, y1 * sy - dy)) \n",
        "            x2 = min(0.999, max(0, x2 * sx - dx))\n",
        "            y2 = min(0.999, max(0, y2 * sy - dy))\n",
        "            \n",
        "            bs[i][1] = (x1 + x2)/2\n",
        "            bs[i][2] = (y1 + y2)/2\n",
        "            bs[i][3] = (x2 - x1)\n",
        "            bs[i][4] = (y2 - y1)\n",
        "\n",
        "            if flip:\n",
        "                bs[i][1] =  0.999 - bs[i][1] \n",
        "            \n",
        "            if bs[i][3] < 0.001 or bs[i][4] < 0.001:\n",
        "                continue\n",
        "            label[cc] = bs[i]\n",
        "            cc += 1\n",
        "            if cc >= 50:\n",
        "                break\n",
        "\n",
        "    label = np.reshape(label, (-1))\n",
        "    return label\n",
        "\n",
        "def load_data_detection(imgpath, shape, jitter, hue, saturation, exposure):\n",
        "    labpath = imgpath.replace('images', 'labels').replace('JPEGImages', 'labels').replace('.jpg', '.txt').replace('.png','.txt')\n",
        "\n",
        "    ## data augmentation\n",
        "    img = Image.open(imgpath).convert('RGB')\n",
        "    img,flip,dx,dy,sx,sy = data_augmentation(img, shape, jitter, hue, saturation, exposure)\n",
        "    label = fill_truth_detection(labpath, img.width, img.height, flip, dx, dy, 1./sx, 1./sy)\n",
        "    return img,label\n",
        "\n",
        "\n",
        "## --------------------------------------- PASCAL VOC - v1 --------------------------------------- ##\n",
        "\n",
        "class YoloDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, dir_data, file_annotations\n",
        "                 , train\n",
        "                 , image_size, grid_num\n",
        "                 , flag_augm\n",
        "                 , transform):\n",
        "        \n",
        "        self.dir_data   = dir_data\n",
        "        self.dir_img    = os.path.join(dir_data, 'JPEGImages')\n",
        "        self.train      = train\n",
        "        self.transform  = transform\n",
        "        \n",
        "        self.fnames     = []\n",
        "        self.boxes      = []\n",
        "        self.labels     = []\n",
        "        self.mean       = (123,117,104) # RGB ([How?])\n",
        "        \n",
        "        self.grid_num   = grid_num\n",
        "        self.image_size = image_size\n",
        "        self.flag_augm  = flag_augm\n",
        "\n",
        "        self.verbose_aug = False\n",
        "\n",
        "        with open(file_annotations) as f:\n",
        "            for line in f.readlines():\n",
        "                splited   = line.strip().split()\n",
        "                self.fnames.append(splited[0])\n",
        "                num_boxes = (len(splited) - 1) // 5\n",
        "                box       = []\n",
        "                label     = []\n",
        "                for i in range(num_boxes):\n",
        "                    x  = float(splited[1+5*i])\n",
        "                    y  = float(splited[2+5*i])\n",
        "                    x2 = float(splited[3+5*i])\n",
        "                    y2 = float(splited[4+5*i])\n",
        "                    c  = splited[5+5*i]\n",
        "                    box.append([x,y,x2,y2])\n",
        "                    label.append(int(c)+1)\n",
        "                self.boxes.append(torch.Tensor(box))\n",
        "                self.labels.append(torch.LongTensor(label))\n",
        "                \n",
        "        self.num_samples = len(self.boxes)\n",
        "    \n",
        "    def __getitem__(self,idx, verbose=0):\n",
        "        fname  = self.fnames[idx]\n",
        "        img    = cv2.imread(os.path.join(self.dir_img, fname), cv2.IMREAD_UNCHANGED)\n",
        "        boxes  = self.boxes[idx].clone()\n",
        "        labels = self.labels[idx].clone()\n",
        "        \n",
        "        if (0):\n",
        "            print (' - fname :', fname)\n",
        "            print (' - path : ', os.path.join(self.dir_img, fname))\n",
        "            # plt.imshow(img)\n",
        "            print (' - labels : ', labels)\n",
        "        \n",
        "        if self.train:\n",
        "            if (self.flag_augm == 1):\n",
        "                img = self.random_bright(img)\n",
        "                img, boxes       = self.random_flip(img, boxes)\n",
        "                img,boxes        = self.randomScale(img,boxes)\n",
        "                img              = self.randomBlur(img)\n",
        "                img              = self.RandomBrightness(img)\n",
        "                img              = self.RandomHue(img)\n",
        "                img              = self.RandomSaturation(img)\n",
        "                img,boxes,labels = self.randomShift(img,boxes,labels)\n",
        "                img,boxes,labels = self.randomCrop(img,boxes,labels)\n",
        "\n",
        "        h,w,_  = img.shape\n",
        "        \n",
        "        boxes  /= torch.Tensor([w,h,w,h]).expand_as(boxes)\n",
        "        img    = self.BGR2RGB(img) #because pytorch pretrained model use RGB\n",
        "        #img    = self.subMean(img,self.mean) \n",
        "        img    = cv2.resize(img,(self.image_size,self.image_size))\n",
        "        target = self.encoder(boxes,labels) # 7x7x30\n",
        "        for t in self.transform:\n",
        "            img = t(img)\n",
        "        return img,target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "    \n",
        "    def encoder(self,boxes,labels):\n",
        "        '''\n",
        "        boxes (tensor) [[x1,y1,x2,y2],[]]\n",
        "        labels (tensor) [...]\n",
        "        return 7x7x30\n",
        "        '''\n",
        "        \n",
        "        target    = torch.zeros((self.grid_num, self.grid_num,30))\n",
        "        cell_size = 1./self.grid_num\n",
        "        wh        = boxes[:,2:] - boxes[:,:2]\n",
        "        cxcy      = (boxes[:,2:] + boxes[:,:2])/2\n",
        "        for i in range(cxcy.size()[0]):\n",
        "            cxcy_sample                       = cxcy[i]\n",
        "            ij                                = (cxcy_sample/cell_size).ceil()-1 #\n",
        "            target[int(ij[1]),int(ij[0]),4]   = 1\n",
        "            target[int(ij[1]),int(ij[0]),9]   = 1\n",
        "            target[int(ij[1]),int(ij[0]),int(labels[i])+9] = 1\n",
        "            xy                                = ij*cell_size # The relative coordinates of the upper left corner of the matched mesh\n",
        "            delta_xy                          = (cxcy_sample -xy)/cell_size\n",
        "            target[int(ij[1]),int(ij[0]),2:4] = wh[i]\n",
        "            target[int(ij[1]),int(ij[0]),:2]  = delta_xy\n",
        "            target[int(ij[1]),int(ij[0]),7:9] = wh[i]\n",
        "            target[int(ij[1]),int(ij[0]),5:7] = delta_xy\n",
        "            \n",
        "        return target\n",
        "    \n",
        "    def BGR2RGB(self,img):\n",
        "        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    def BGR2HSV(self,img):\n",
        "        return cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
        "    def HSV2BGR(self,img):\n",
        "        return cv2.cvtColor(img,cv2.COLOR_HSV2BGR)\n",
        "    \n",
        "    def subMean(self,bgr,mean):\n",
        "        mean = np.array(mean, dtype=np.float32)\n",
        "        bgr  = bgr - mean\n",
        "        return bgr\n",
        "    \n",
        "    def RandomBrightness(self,bgr):\n",
        "        if random.random() < 0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomBrightness')\n",
        "            hsv = self.BGR2HSV(bgr)\n",
        "            h,s,v = cv2.split(hsv)\n",
        "            adjust = random.choice([0.5,1.5])\n",
        "            v = v*adjust\n",
        "            v = np.clip(v, 0, 255).astype(hsv.dtype)\n",
        "            hsv = cv2.merge((h,s,v))\n",
        "            bgr = self.HSV2BGR(hsv)\n",
        "        return bgr\n",
        "    \n",
        "    def RandomSaturation(self,bgr):\n",
        "        if random.random() < 0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomSaturation')\n",
        "            hsv = self.BGR2HSV(bgr)\n",
        "            h,s,v = cv2.split(hsv)\n",
        "            adjust = random.choice([0.5,1.5])\n",
        "            s = s*adjust\n",
        "            s = np.clip(s, 0, 255).astype(hsv.dtype)\n",
        "            hsv = cv2.merge((h,s,v))\n",
        "            bgr = self.HSV2BGR(hsv)\n",
        "        return bgr\n",
        "    \n",
        "    def RandomHue(self,bgr):\n",
        "        if random.random() < 0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomHue')\n",
        "            hsv = self.BGR2HSV(bgr)\n",
        "            h,s,v = cv2.split(hsv)\n",
        "            adjust = random.choice([0.5,1.5])\n",
        "            h = h*adjust\n",
        "            h = np.clip(h, 0, 255).astype(hsv.dtype)\n",
        "            hsv = cv2.merge((h,s,v))\n",
        "            bgr = self.HSV2BGR(hsv)\n",
        "        return bgr\n",
        "\n",
        "    def randomBlur(self,bgr):\n",
        "        if random.random()<0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomBlur')\n",
        "            bgr = cv2.blur(bgr,(5,5))\n",
        "        return bgr\n",
        "\n",
        "    def randomShift(self,bgr,boxes,labels):\n",
        "        #平移变换\n",
        "        center = (boxes[:,2:]+boxes[:,:2])/2\n",
        "        if random.random() <0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomShift')\n",
        "            height,width,c = bgr.shape\n",
        "            after_shfit_image = np.zeros((height,width,c),dtype=bgr.dtype)\n",
        "            after_shfit_image[:,:,:] = (104,117,123) #bgr\n",
        "            shift_x = random.uniform(-width*0.2,width*0.2)\n",
        "            shift_y = random.uniform(-height*0.2,height*0.2)\n",
        "            #print(bgr.shape,shift_x,shift_y)\n",
        "            #原图像的平移\n",
        "            if shift_x>=0 and shift_y>=0:\n",
        "                after_shfit_image[int(shift_y):,int(shift_x):,:] = bgr[:height-int(shift_y),:width-int(shift_x),:]\n",
        "            elif shift_x>=0 and shift_y<0:\n",
        "                after_shfit_image[:height+int(shift_y),int(shift_x):,:] = bgr[-int(shift_y):,:width-int(shift_x),:]\n",
        "            elif shift_x <0 and shift_y >=0:\n",
        "                after_shfit_image[int(shift_y):,:width+int(shift_x),:] = bgr[:height-int(shift_y),-int(shift_x):,:]\n",
        "            elif shift_x<0 and shift_y<0:\n",
        "                after_shfit_image[:height+int(shift_y),:width+int(shift_x),:] = bgr[-int(shift_y):,-int(shift_x):,:]\n",
        "\n",
        "            shift_xy = torch.FloatTensor([[int(shift_x),int(shift_y)]]).expand_as(center)\n",
        "            center = center + shift_xy\n",
        "            mask1 = (center[:,0] >0) & (center[:,0] < width)\n",
        "            mask2 = (center[:,1] >0) & (center[:,1] < height)\n",
        "            mask = (mask1 & mask2).view(-1,1)\n",
        "            boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n",
        "            if len(boxes_in) == 0:\n",
        "                return bgr,boxes,labels\n",
        "            box_shift = torch.FloatTensor([[int(shift_x),int(shift_y),int(shift_x),int(shift_y)]]).expand_as(boxes_in)\n",
        "            boxes_in = boxes_in+box_shift\n",
        "            labels_in = labels[mask.view(-1)]\n",
        "            return after_shfit_image,boxes_in,labels_in\n",
        "        return bgr,boxes,labels\n",
        "\n",
        "    def randomScale(self,bgr,boxes):\n",
        "        #固定住高度，以0.8-1.2伸缩宽度，做图像形变\n",
        "        if random.random() < 0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomScale')\n",
        "            scale = random.uniform(0.8,1.2)\n",
        "            height,width,c = bgr.shape\n",
        "            bgr = cv2.resize(bgr,(int(width*scale),height))\n",
        "            scale_tensor = torch.FloatTensor([[scale,1,scale,1]]).expand_as(boxes)\n",
        "            boxes = boxes * scale_tensor\n",
        "            return bgr,boxes\n",
        "        return bgr,boxes\n",
        "\n",
        "    def randomCrop(self,bgr,boxes,labels):\n",
        "        if random.random() < 0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : randomCrop')\n",
        "            center = (boxes[:,2:]+boxes[:,:2])/2\n",
        "            height,width,c = bgr.shape\n",
        "            h = random.uniform(0.6*height,height)\n",
        "            w = random.uniform(0.6*width,width)\n",
        "            x = random.uniform(0,width-w)\n",
        "            y = random.uniform(0,height-h)\n",
        "            x,y,h,w = int(x),int(y),int(h),int(w)\n",
        "\n",
        "            center = center - torch.FloatTensor([[x,y]]).expand_as(center)\n",
        "            mask1 = (center[:,0]>0) & (center[:,0]<w)\n",
        "            mask2 = (center[:,1]>0) & (center[:,1]<h)\n",
        "            mask = (mask1 & mask2).view(-1,1)\n",
        "\n",
        "            boxes_in = boxes[mask.expand_as(boxes)].view(-1,4)\n",
        "            if(len(boxes_in)==0):\n",
        "                return bgr,boxes,labels\n",
        "            box_shift = torch.FloatTensor([[x,y,x,y]]).expand_as(boxes_in)\n",
        "\n",
        "            boxes_in = boxes_in - box_shift\n",
        "            boxes_in[:,0]=boxes_in[:,0].clamp_(min=0,max=w)\n",
        "            boxes_in[:,2]=boxes_in[:,2].clamp_(min=0,max=w)\n",
        "            boxes_in[:,1]=boxes_in[:,1].clamp_(min=0,max=h)\n",
        "            boxes_in[:,3]=boxes_in[:,3].clamp_(min=0,max=h)\n",
        "\n",
        "            labels_in = labels[mask.view(-1)]\n",
        "            img_croped = bgr[y:y+h,x:x+w,:]\n",
        "            return img_croped,boxes_in,labels_in\n",
        "        return bgr,boxes,labels\n",
        "    \n",
        "    def random_flip(self, im, boxes):\n",
        "        if random.random() < 0.5:\n",
        "            if self.verbose_aug:\n",
        "                print (' - [AUG] : random_flip')\n",
        "            im_lr = np.fliplr(im).copy()\n",
        "            h,w,_ = im.shape\n",
        "            xmin = w - boxes[:,2]\n",
        "            xmax = w - boxes[:,0]\n",
        "            boxes[:,0] = xmin\n",
        "            boxes[:,2] = xmax\n",
        "            return im_lr, boxes\n",
        "        return im, boxes\n",
        "    \n",
        "    def random_bright(self, im, delta=16):\n",
        "        alpha = random.random()\n",
        "        if alpha > 0.3:\n",
        "            im = im * alpha + random.randrange(-delta,delta)\n",
        "            im = im.clip(min=0,max=255).astype(np.uint8)\n",
        "        return im\n",
        "\n",
        "    def display(self, X):\n",
        "        plt.imshow(X.data.numpy().transpose(1,2,0))\n",
        "    \n",
        "    def display_anno(self, X,y):\n",
        "        pass\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqDc-ijKM2yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nets2_util\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import struct # get_image_size\n",
        "import imghdr # get_image_size\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(math.exp(-x)+1.)\n",
        "\n",
        "def softmax(x):\n",
        "    x = torch.exp(x - torch.max(x))\n",
        "    x = x/x.sum()\n",
        "    return x\n",
        "\n",
        "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
        "    if x1y1x2y2:\n",
        "        mx = min(box1[0], box2[0])\n",
        "        Mx = max(box1[2], box2[2])\n",
        "        my = min(box1[1], box2[1])\n",
        "        My = max(box1[3], box2[3])\n",
        "        w1 = box1[2] - box1[0]\n",
        "        h1 = box1[3] - box1[1]\n",
        "        w2 = box2[2] - box2[0]\n",
        "        h2 = box2[3] - box2[1]\n",
        "    else:\n",
        "        mx = min(box1[0]-box1[2]/2.0, box2[0]-box2[2]/2.0)\n",
        "        Mx = max(box1[0]+box1[2]/2.0, box2[0]+box2[2]/2.0)\n",
        "        my = min(box1[1]-box1[3]/2.0, box2[1]-box2[3]/2.0)\n",
        "        My = max(box1[1]+box1[3]/2.0, box2[1]+box2[3]/2.0)\n",
        "        w1 = box1[2]\n",
        "        h1 = box1[3]\n",
        "        w2 = box2[2]\n",
        "        h2 = box2[3]\n",
        "    uw = Mx - mx\n",
        "    uh = My - my\n",
        "    cw = w1 + w2 - uw\n",
        "    ch = h1 + h2 - uh\n",
        "    carea = 0\n",
        "    if cw <= 0 or ch <= 0:\n",
        "        return 0.0\n",
        "\n",
        "    area1 = w1 * h1\n",
        "    area2 = w2 * h2\n",
        "    carea = cw * ch\n",
        "    uarea = area1 + area2 - carea\n",
        "    return carea/uarea\n",
        "\n",
        "def bbox_ious(boxes1, boxes2, x1y1x2y2=True):\n",
        "    if x1y1x2y2:\n",
        "        mx = torch.min(boxes1[0], boxes2[0])\n",
        "        Mx = torch.max(boxes1[2], boxes2[2])\n",
        "        my = torch.min(boxes1[1], boxes2[1])\n",
        "        My = torch.max(boxes1[3], boxes2[3])\n",
        "        w1 = boxes1[2] - boxes1[0]\n",
        "        h1 = boxes1[3] - boxes1[1]\n",
        "        w2 = boxes2[2] - boxes2[0]\n",
        "        h2 = boxes2[3] - boxes2[1]\n",
        "    else:\n",
        "        mx = torch.min(boxes1[0]-boxes1[2]/2.0, boxes2[0]-boxes2[2]/2.0)\n",
        "        Mx = torch.max(boxes1[0]+boxes1[2]/2.0, boxes2[0]+boxes2[2]/2.0)\n",
        "        my = torch.min(boxes1[1]-boxes1[3]/2.0, boxes2[1]-boxes2[3]/2.0)\n",
        "        My = torch.max(boxes1[1]+boxes1[3]/2.0, boxes2[1]+boxes2[3]/2.0)\n",
        "        w1 = boxes1[2]\n",
        "        h1 = boxes1[3]\n",
        "        w2 = boxes2[2]\n",
        "        h2 = boxes2[3]\n",
        "    uw = Mx - mx\n",
        "    uh = My - my\n",
        "    cw = w1 + w2 - uw\n",
        "    ch = h1 + h2 - uh\n",
        "    mask = ((cw <= 0) + (ch <= 0) > 0)\n",
        "    area1 = w1 * h1\n",
        "    area2 = w2 * h2\n",
        "    carea = cw * ch\n",
        "    carea[mask] = 0\n",
        "    uarea = area1 + area2 - carea\n",
        "    return carea/uarea\n",
        "\n",
        "def nms(boxes, nms_thresh):\n",
        "    if len(boxes) == 0:\n",
        "        return boxes\n",
        "\n",
        "    det_confs = torch.zeros(len(boxes))\n",
        "    for i in range(len(boxes)):\n",
        "        det_confs[i] = 1-boxes[i][4]                \n",
        "\n",
        "    _,sortIds = torch.sort(det_confs)\n",
        "    out_boxes = []\n",
        "    for i in range(len(boxes)):\n",
        "        box_i = boxes[sortIds[i]]\n",
        "        if box_i[4] > 0:\n",
        "            out_boxes.append(box_i)\n",
        "            for j in range(i+1, len(boxes)):\n",
        "                box_j = boxes[sortIds[j]]\n",
        "                if bbox_iou(box_i, box_j, x1y1x2y2=False) > nms_thresh:\n",
        "                    #print(box_i, box_j, bbox_iou(box_i, box_j, x1y1x2y2=False))\n",
        "                    box_j[4] = 0\n",
        "    return out_boxes\n",
        "\n",
        "def convert2cpu(gpu_matrix):\n",
        "    return torch.FloatTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
        "\n",
        "def convert2cpu_long(gpu_matrix):\n",
        "    return torch.LongTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
        "\n",
        "def get_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors, only_objectness=1, validation=False):\n",
        "    anchor_step = int(len(anchors)/num_anchors)\n",
        "    if output.dim() == 3:\n",
        "        output = output.unsqueeze(0)\n",
        "    batch = output.size(0)\n",
        "    assert(output.size(1) == (5+num_classes)*num_anchors)\n",
        "    h = output.size(2)\n",
        "    w = output.size(3)\n",
        "\n",
        "    t0 = time.time()\n",
        "    all_boxes = []\n",
        "    output = output.view(batch*num_anchors, 5+num_classes, h*w).transpose(0,1).contiguous().view(5+num_classes, batch*num_anchors*h*w)\n",
        "\n",
        "    grid_x = torch.linspace(0, w-1, w).repeat(h,1).repeat(batch*num_anchors, 1, 1).view(batch*num_anchors*h*w).cuda()\n",
        "    grid_y = torch.linspace(0, h-1, h).repeat(w,1).t().repeat(batch*num_anchors, 1, 1).view(batch*num_anchors*h*w).cuda()\n",
        "    xs = torch.sigmoid(output[0]) + grid_x\n",
        "    ys = torch.sigmoid(output[1]) + grid_y\n",
        "\n",
        "    anchor_w = torch.Tensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([0]))\n",
        "    anchor_h = torch.Tensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([1]))\n",
        "    anchor_w = anchor_w.repeat(batch, 1).repeat(1, 1, h*w).view(batch*num_anchors*h*w).cuda()\n",
        "    anchor_h = anchor_h.repeat(batch, 1).repeat(1, 1, h*w).view(batch*num_anchors*h*w).cuda()\n",
        "    ws = torch.exp(output[2]) * anchor_w\n",
        "    hs = torch.exp(output[3]) * anchor_h\n",
        "\n",
        "    det_confs = torch.sigmoid(output[4])\n",
        "\n",
        "    cls_confs = torch.nn.Softmax()(Variable(output[5:5+num_classes].transpose(0,1))).data\n",
        "    cls_max_confs, cls_max_ids = torch.max(cls_confs, 1)\n",
        "    cls_max_confs = cls_max_confs.view(-1)\n",
        "    cls_max_ids = cls_max_ids.view(-1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    sz_hw = h*w\n",
        "    sz_hwa = sz_hw*num_anchors\n",
        "    det_confs = convert2cpu(det_confs)\n",
        "    cls_max_confs = convert2cpu(cls_max_confs)\n",
        "    cls_max_ids = convert2cpu_long(cls_max_ids)\n",
        "    xs = convert2cpu(xs)\n",
        "    ys = convert2cpu(ys)\n",
        "    ws = convert2cpu(ws)\n",
        "    hs = convert2cpu(hs)\n",
        "    if validation:\n",
        "        cls_confs = convert2cpu(cls_confs.view(-1, num_classes))\n",
        "    t2 = time.time()\n",
        "    for b in range(batch):\n",
        "        boxes = []\n",
        "        for cy in range(h):\n",
        "            for cx in range(w):\n",
        "                for i in range(num_anchors):\n",
        "                    ind = b*sz_hwa + i*sz_hw + cy*w + cx\n",
        "                    det_conf =  det_confs[ind]\n",
        "                    if only_objectness:\n",
        "                        conf =  det_confs[ind]\n",
        "                    else:\n",
        "                        conf = det_confs[ind] * cls_max_confs[ind]\n",
        "    \n",
        "                    if conf > conf_thresh:\n",
        "                        bcx = xs[ind]\n",
        "                        bcy = ys[ind]\n",
        "                        bw = ws[ind]\n",
        "                        bh = hs[ind]\n",
        "                        cls_max_conf = cls_max_confs[ind]\n",
        "                        cls_max_id = cls_max_ids[ind]\n",
        "                        box = [bcx/w, bcy/h, bw/w, bh/h, det_conf, cls_max_conf, cls_max_id]\n",
        "                        if (not only_objectness) and validation:\n",
        "                            for c in range(num_classes):\n",
        "                                tmp_conf = cls_confs[ind][c]\n",
        "                                if c != cls_max_id and det_confs[ind]*tmp_conf > conf_thresh:\n",
        "                                    box.append(tmp_conf)\n",
        "                                    box.append(c)\n",
        "                        boxes.append(box)\n",
        "        all_boxes.append(boxes)\n",
        "    t3 = time.time()\n",
        "    if False:\n",
        "        print('---------------------------------')\n",
        "        print('matrix computation : %f' % (t1-t0))\n",
        "        print('        gpu to cpu : %f' % (t2-t1))\n",
        "        print('      boxes filter : %f' % (t3-t2))\n",
        "        print('---------------------------------')\n",
        "    return all_boxes\n",
        "\n",
        "def plot_boxes_cv2(img, boxes, savename=None, class_names=None, color=None):\n",
        "    import cv2\n",
        "    colors = torch.FloatTensor([[1,0,1],[0,0,1],[0,1,1],[0,1,0],[1,1,0],[1,0,0]]);\n",
        "    def get_color(c, x, max_val):\n",
        "        ratio = float(x)/max_val * 5\n",
        "        i = int(math.floor(ratio))\n",
        "        j = int(math.ceil(ratio))\n",
        "        ratio = ratio - i\n",
        "        r = (1-ratio) * colors[i][c] + ratio*colors[j][c]\n",
        "        return int(r*255)\n",
        "\n",
        "    width = img.shape[1]\n",
        "    height = img.shape[0]\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        x1 = int(round((box[0] - box[2]/2.0) * width))\n",
        "        y1 = int(round((box[1] - box[3]/2.0) * height))\n",
        "        x2 = int(round((box[0] + box[2]/2.0) * width))\n",
        "        y2 = int(round((box[1] + box[3]/2.0) * height))\n",
        "\n",
        "        if color:\n",
        "            rgb = color\n",
        "        else:\n",
        "            rgb = (255, 0, 0)\n",
        "        if len(box) >= 7 and class_names:\n",
        "            cls_conf = box[5]\n",
        "            cls_id = box[6]\n",
        "            print('%s: %f' % (class_names[cls_id], cls_conf))\n",
        "            classes = len(class_names)\n",
        "            offset = cls_id * 123457 % classes\n",
        "            red   = get_color(2, offset, classes)\n",
        "            green = get_color(1, offset, classes)\n",
        "            blue  = get_color(0, offset, classes)\n",
        "            if color is None:\n",
        "                rgb = (red, green, blue)\n",
        "            img = cv2.putText(img, class_names[cls_id], (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 1.2, rgb, 1)\n",
        "        img = cv2.rectangle(img, (x1,y1), (x2,y2), rgb, 1)\n",
        "    if savename:\n",
        "        print(\"save plot results to %s\" % savename)\n",
        "        cv2.imwrite(savename, img)\n",
        "    return img\n",
        "\n",
        "def plot_boxes(img, boxes, savename=None, class_names=None):\n",
        "    colors = torch.FloatTensor([[1,0,1],[0,0,1],[0,1,1],[0,1,0],[1,1,0],[1,0,0]]);\n",
        "    def get_color(c, x, max_val):\n",
        "        ratio = float(x)/max_val * 5\n",
        "        i = int(math.floor(ratio))\n",
        "        j = int(math.ceil(ratio))\n",
        "        ratio = ratio - i\n",
        "        r = (1-ratio) * colors[i][c] + ratio*colors[j][c]\n",
        "        return int(r*255)\n",
        "\n",
        "    width = img.width\n",
        "    height = img.height\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        x1 = (box[0] - box[2]/2.0) * width\n",
        "        y1 = (box[1] - box[3]/2.0) * height\n",
        "        x2 = (box[0] + box[2]/2.0) * width\n",
        "        y2 = (box[1] + box[3]/2.0) * height\n",
        "\n",
        "        rgb = (255, 0, 0)\n",
        "        if len(box) >= 7 and class_names:\n",
        "            cls_conf = box[5]\n",
        "            cls_id = box[6]\n",
        "            print (' - cls_id : ', cls_id)\n",
        "            print('%s: %f' % (class_names[cls_id], cls_conf))\n",
        "            classes = len(class_names)\n",
        "            offset = cls_id * 123457 % classes\n",
        "            red   = get_color(2, offset, classes)\n",
        "            green = get_color(1, offset, classes)\n",
        "            blue  = get_color(0, offset, classes)\n",
        "            rgb = (red, green, blue)\n",
        "            draw.text((x1, y1), class_names[cls_id], fill=rgb)\n",
        "        draw.rectangle([x1, y1, x2, y2], outline = rgb)\n",
        "    if savename:\n",
        "        print(\"save plot results to %s\" % savename)\n",
        "        img.save(savename)\n",
        "    return img\n",
        "\n",
        "def read_truths(lab_path):\n",
        "    if not os.path.exists(lab_path):\n",
        "        return np.array([])\n",
        "    if os.path.getsize(lab_path):\n",
        "        truths = np.loadtxt(lab_path)\n",
        "        truths = truths.reshape(truths.size/5, 5) # to avoid single truth problem\n",
        "        return truths\n",
        "    else:\n",
        "        return np.array([])\n",
        "\n",
        "def read_truths_args(lab_path, min_box_scale):\n",
        "    truths = read_truths(lab_path)\n",
        "    new_truths = []\n",
        "    for i in range(truths.shape[0]):\n",
        "        if truths[i][3] < min_box_scale:\n",
        "            continue\n",
        "        new_truths.append([truths[i][0], truths[i][1], truths[i][2], truths[i][3], truths[i][4]])\n",
        "    return np.array(new_truths)\n",
        "\n",
        "def load_class_names(namesfile):\n",
        "    class_names = []\n",
        "    with open(namesfile, 'r') as fp:\n",
        "        lines = fp.readlines()\n",
        "    for line in lines:\n",
        "        line = line.rstrip()\n",
        "        class_names.append(line)\n",
        "    return class_names\n",
        "\n",
        "def image2torch(img):\n",
        "    width = img.width\n",
        "    height = img.height\n",
        "    img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
        "    img = img.view(height, width, 3).transpose(0,1).transpose(0,2).contiguous()\n",
        "    img = img.view(1, 3, height, width)\n",
        "    img = img.float().div(255.0)\n",
        "    return img\n",
        "\n",
        "def do_detect(model, img, conf_thresh, nms_thresh, use_cuda=1):\n",
        "    model.eval()\n",
        "    t0 = time.time()\n",
        "\n",
        "    if isinstance(img, Image.Image):\n",
        "        width = img.width\n",
        "        height = img.height\n",
        "        img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
        "        img = img.view(height, width, 3).transpose(0,1).transpose(0,2).contiguous()\n",
        "        img = img.view(1, 3, height, width)\n",
        "        img = img.float().div(255.0)\n",
        "    elif type(img) == np.ndarray: # cv2 image\n",
        "        img = torch.from_numpy(img.transpose(2,0,1)).float().div(255.0).unsqueeze(0)\n",
        "    else:\n",
        "        print(\"unknow image type\")\n",
        "        exit(-1)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    if use_cuda:\n",
        "        img = img.cuda()\n",
        "    img = torch.autograd.Variable(img)\n",
        "    t2 = time.time()\n",
        "\n",
        "    output = model(img)\n",
        "    output = output.data\n",
        "    #for j in range(100):\n",
        "    #    sys.stdout.write('%f ' % (output.storage()[j]))\n",
        "    #print('')\n",
        "    t3 = time.time()\n",
        "\n",
        "    boxes = get_region_boxes(output, conf_thresh, model.num_classes, model.anchors, model.num_anchors)[0]\n",
        "    #for j in range(len(boxes)):\n",
        "    #    print(boxes[j])\n",
        "    t4 = time.time()\n",
        "\n",
        "    boxes = nms(boxes, nms_thresh)\n",
        "    t5 = time.time()\n",
        "\n",
        "    if False:\n",
        "        print('-----------------------------------')\n",
        "        print(' image to tensor : %f' % (t1 - t0))\n",
        "        print('  tensor to cuda : %f' % (t2 - t1))\n",
        "        print('         predict : %f' % (t3 - t2))\n",
        "        print('get_region_boxes : %f' % (t4 - t3))\n",
        "        print('             nms : %f' % (t5 - t4))\n",
        "        print('           total : %f' % (t5 - t0))\n",
        "        print('-----------------------------------')\n",
        "    return boxes\n",
        "\n",
        "def read_data_cfg(datacfg):\n",
        "    options = dict()\n",
        "    options['gpus'] = '0,1,2,3'\n",
        "    options['num_workers'] = '10'\n",
        "    with open(datacfg, 'r') as fp:\n",
        "        lines = fp.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line == '':\n",
        "            continue\n",
        "        key,value = line.split('=')\n",
        "        key = key.strip()\n",
        "        value = value.strip()\n",
        "        options[key] = value\n",
        "    return options\n",
        "\n",
        "def scale_bboxes(bboxes, width, height):\n",
        "    import copy\n",
        "    dets = copy.deepcopy(bboxes)\n",
        "    for i in range(len(dets)):\n",
        "        dets[i][0] = dets[i][0] * width\n",
        "        dets[i][1] = dets[i][1] * height\n",
        "        dets[i][2] = dets[i][2] * width\n",
        "        dets[i][3] = dets[i][3] * height\n",
        "    return dets\n",
        "      \n",
        "def file_lines(thefilepath):\n",
        "    count = 0\n",
        "    thefile = open(thefilepath, 'rb')\n",
        "    while True:\n",
        "        buffer = thefile.read(8192*1024)\n",
        "        if not buffer:\n",
        "            break\n",
        "        count += buffer.count(b'\\n')\n",
        "    thefile.close( )\n",
        "    return count\n",
        "\n",
        "def get_image_size(fname):\n",
        "    '''Determine the image type of fhandle and return its size.\n",
        "    from draco'''\n",
        "    with open(fname, 'rb') as fhandle:\n",
        "        head = fhandle.read(24)\n",
        "        if len(head) != 24: \n",
        "            return\n",
        "        if imghdr.what(fname) == 'png':\n",
        "            check = struct.unpack('>i', head[4:8])[0]\n",
        "            if check != 0x0d0a1a0a:\n",
        "                return\n",
        "            width, height = struct.unpack('>ii', head[16:24])\n",
        "        elif imghdr.what(fname) == 'gif':\n",
        "            width, height = struct.unpack('<HH', head[6:10])\n",
        "        elif imghdr.what(fname) == 'jpeg' or imghdr.what(fname) == 'jpg':\n",
        "            try:\n",
        "                fhandle.seek(0) # Read 0xff next\n",
        "                size = 2 \n",
        "                ftype = 0 \n",
        "                while not 0xc0 <= ftype <= 0xcf:\n",
        "                    fhandle.seek(size, 1)\n",
        "                    byte = fhandle.read(1)\n",
        "                    while ord(byte) == 0xff:\n",
        "                        byte = fhandle.read(1)\n",
        "                    ftype = ord(byte)\n",
        "                    size = struct.unpack('>H', fhandle.read(2))[0] - 2 \n",
        "                # We are at a SOFn block\n",
        "                fhandle.seek(1, 1)  # Skip `precision' byte.\n",
        "                height, width = struct.unpack('>HH', fhandle.read(4))\n",
        "            except Exception: #IGNORE:W0703\n",
        "                return\n",
        "        else:\n",
        "            return\n",
        "        return width, height\n",
        "\n",
        "def logging(message):\n",
        "    print('%s %s' % (time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()), message))\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     file = '/home/strider/Work/Netherlands/TUDelft/1_Courses/Sem2/DeepLearning/Project/repo1/data/dataset/voc.names'\n",
        "#     class_names = load_class_names(file)\n",
        "#     print (class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l40ba7zfNCbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0eebb93f-08d2-47e0-8292-2184ff3e4b50"
      },
      "source": [
        "# nets\n",
        "\n",
        "#encoding:utf-8\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import traceback\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "# print (os.getcwd())\n",
        "# from src.nets2_utils import *\n",
        "# from .nets2_utils import *\n",
        "\n",
        "# from pruning.weightPruning.layers import MaskedLinear\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "## --------------------------------------- YOLOV2 --------------------------------------- ##\n",
        "\n",
        "## ----------------- YOLOV2:cfg\n",
        "def parse_cfg(cfgfile, verbose=0):\n",
        "    blocks = []\n",
        "    fp     = open(cfgfile, 'r')\n",
        "    block  =  None\n",
        "    line   = fp.readline()\n",
        "    while line != '':\n",
        "        line = line.rstrip()\n",
        "        if line == '' or line[0] == '#':\n",
        "            line = fp.readline()\n",
        "            continue\n",
        "\n",
        "        elif line[0] == '[':\n",
        "            if block:\n",
        "                if verbose:\n",
        "                    print ('')\n",
        "                    print (' - block : ', block)\n",
        "                blocks.append(block)\n",
        "            block = dict()\n",
        "            block['type'] = line.lstrip('[').rstrip(']')\n",
        "            # set default value\n",
        "            if block['type'] == 'convolutional':\n",
        "                block['batch_normalize'] = 0\n",
        "        else:\n",
        "            key,value = line.split('=')\n",
        "            key = key.strip()\n",
        "            if key == 'type':\n",
        "                key = '_type'\n",
        "            value = value.strip()\n",
        "            block[key] = value\n",
        "        line = fp.readline()\n",
        "\n",
        "    if block:\n",
        "        blocks.append(block)\n",
        "    fp.close()\n",
        "    return blocks\n",
        "\n",
        "def print_cfg(blocks):\n",
        "    print('layer     filters    size              input                output');\n",
        "    prev_width = 416\n",
        "    prev_height = 416\n",
        "    prev_filters = 3\n",
        "    out_filters =[]\n",
        "    out_widths =[]\n",
        "    out_heights =[]\n",
        "    ind = -2\n",
        "    for block in blocks:\n",
        "        ind = ind + 1\n",
        "        if block['type'] == 'net':\n",
        "            prev_width = int(block['width'])\n",
        "            prev_height = int(block['height'])\n",
        "            continue\n",
        "        elif block['type'] == 'convolutional':\n",
        "            filters = int(block['filters'])\n",
        "            kernel_size = int(block['size'])\n",
        "            stride = int(block['stride'])\n",
        "            is_pad = int(block['pad'])\n",
        "            pad = (kernel_size-1)/2 if is_pad else 0\n",
        "            width = (prev_width + 2*pad - kernel_size)/stride + 1\n",
        "            height = (prev_height + 2*pad - kernel_size)/stride + 1\n",
        "            print('%5d %-6s %4d  %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'conv', filters, kernel_size, kernel_size, stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
        "            prev_width = width\n",
        "            prev_height = height\n",
        "            prev_filters = filters\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'maxpool':\n",
        "            pool_size = int(block['size'])\n",
        "            stride = int(block['stride'])\n",
        "            width = prev_width/stride\n",
        "            height = prev_height/stride\n",
        "            print('%5d %-6s       %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'max', pool_size, pool_size, stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
        "            prev_width = width\n",
        "            prev_height = height\n",
        "            prev_filters = filters\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'avgpool':\n",
        "            width = 1\n",
        "            height = 1\n",
        "            print('%5d %-6s                   %3d x %3d x%4d   ->  %3d' % (ind, 'avg', prev_width, prev_height, prev_filters,  prev_filters))\n",
        "            prev_width = width\n",
        "            prev_height = height\n",
        "            prev_filters = filters\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'softmax':\n",
        "            print('%5d %-6s                                    ->  %3d' % (ind, 'softmax', prev_filters))\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'cost':\n",
        "            print('%5d %-6s                                     ->  %3d' % (ind, 'cost', prev_filters))\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'reorg':\n",
        "            stride = int(block['stride'])\n",
        "            filters = stride * stride * prev_filters\n",
        "            width = prev_width/stride\n",
        "            height = prev_height/stride\n",
        "            print('%5d %-6s             / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'reorg', stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
        "            prev_width = width\n",
        "            prev_height = height\n",
        "            prev_filters = filters\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'route':\n",
        "            layers = block['layers'].split(',')\n",
        "            layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
        "            if len(layers) == 1:\n",
        "                print('%5d %-6s %d' % (ind, 'route', layers[0]))\n",
        "                prev_width = out_widths[layers[0]]\n",
        "                prev_height = out_heights[layers[0]]\n",
        "                prev_filters = out_filters[layers[0]]\n",
        "            elif len(layers) == 2:\n",
        "                print('%5d %-6s %d %d' % (ind, 'route', layers[0], layers[1]))\n",
        "                prev_width = out_widths[layers[0]]\n",
        "                prev_height = out_heights[layers[0]]\n",
        "                assert(prev_width == out_widths[layers[1]])\n",
        "                assert(prev_height == out_heights[layers[1]])\n",
        "                prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'region':\n",
        "            print('%5d %-6s' % (ind, 'detection'))\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'shortcut':\n",
        "            from_id = int(block['from'])\n",
        "            from_id = from_id if from_id > 0 else from_id+ind\n",
        "            print('%5d %-6s %d' % (ind, 'shortcut', from_id))\n",
        "            prev_width = out_widths[from_id]\n",
        "            prev_height = out_heights[from_id]\n",
        "            prev_filters = out_filters[from_id]\n",
        "            out_widths.append(prev_width)\n",
        "            out_heights.append(prev_height)\n",
        "            out_filters.append(prev_filters)\n",
        "        elif block['type'] == 'connected':\n",
        "            filters = int(block['output'])\n",
        "            print('%5d %-6s                            %d  ->  %3d' % (ind, 'connected', prev_filters,  filters))\n",
        "            prev_filters = filters\n",
        "            out_widths.append(1)\n",
        "            out_heights.append(1)\n",
        "            out_filters.append(prev_filters)\n",
        "        else:\n",
        "            print('unknown type %s' % (block['type']))\n",
        "\n",
        "def load_conv_old(buf, start, conv_model):\n",
        "    num_w = conv_model.weight.numel()\n",
        "    num_b = conv_model.bias.numel()\n",
        "    conv_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n",
        "    return start\n",
        "\n",
        "def save_conv(fp, conv_model):\n",
        "    if conv_model.bias.is_cuda:\n",
        "        convert2cpu(conv_model.bias.data).numpy().tofile(fp)\n",
        "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
        "    else:\n",
        "        conv_model.bias.data.numpy().tofile(fp)\n",
        "        conv_model.weight.data.numpy().tofile(fp)\n",
        "\n",
        "def load_conv_bn_old(buf, start, conv_model, bn_model, verbose=0):\n",
        "    num_w = conv_model.weight.numel()\n",
        "    num_b = bn_model.bias.numel()\n",
        "    if (1):\n",
        "        print ('      - conv weights : ', num_w)\n",
        "        print ('      - bias weights : ', num_b)\n",
        "        print ('      - bn_model.bias : ', bn_model.bias.shape)\n",
        "        print ('      - bn_model.weight : ', bn_model.weight.shape)\n",
        "    \n",
        "    bn_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n",
        "    bn_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    bn_model.running_mean.copy_(torch.from_numpy(buf[start:start+num_b]));  start = start + num_b\n",
        "    bn_model.running_var.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    \n",
        "    if (1):\n",
        "        print ('      - start : ', start)\n",
        "        print ('      - size :  ', buf[start:start+num_w].shape)\n",
        "        print ('      - shape :  ', conv_model.weight.data.shape)\n",
        "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w \n",
        "    \n",
        "    return start\n",
        "\n",
        "def save_conv_bn(fp, conv_model, bn_model):\n",
        "    if bn_model.bias.is_cuda:\n",
        "        convert2cpu(bn_model.bias.data).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.weight.data).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.running_mean).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.running_var).numpy().tofile(fp)\n",
        "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
        "    else:\n",
        "        bn_model.bias.data.numpy().tofile(fp)\n",
        "        bn_model.weight.data.numpy().tofile(fp)\n",
        "        bn_model.running_mean.numpy().tofile(fp)\n",
        "        bn_model.running_var.numpy().tofile(fp)\n",
        "        conv_model.weight.data.numpy().tofile(fp)\n",
        "\n",
        "def load_fc(buf, start, fc_model):\n",
        "    num_w = fc_model.weight.numel()\n",
        "    num_b = fc_model.bias.numel()\n",
        "    fc_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n",
        "    fc_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]));   start = start + num_w \n",
        "    return start\n",
        "\n",
        "def save_fc(fp, fc_model):\n",
        "    fc_model.bias.data.numpy().tofile(fp)\n",
        "    fc_model.weight.data.numpy().tofile(fp)\n",
        "\n",
        "def load_param(file, param):\n",
        "    param.data.copy_(torch.from_numpy(\n",
        "        np.fromfile(file, dtype=np.float32, count=param.numel()).reshape(param.shape)\n",
        "    ))\n",
        "\n",
        "def load_conv(file, conv_model):\n",
        "    load_param(file, conv_model.bias)\n",
        "    load_param(file, conv_model.weight)\n",
        "\n",
        "def load_conv_bn(file, conv_model, bn_model):\n",
        "    load_param(file, bn_model.bias)\n",
        "    load_param(file, bn_model.weight)\n",
        "    load_param(file, bn_model.running_mean)\n",
        "    load_param(file, bn_model.running_var)\n",
        "    load_param(file, conv_model.weight)\n",
        "\n",
        "\n",
        "## ----------------- YOLOV2:modelling\n",
        "def build_targets(pred_boxes, target, anchors, num_anchors, num_classes, nH, nW, noobject_scale, object_scale, sil_thresh, seen):\n",
        "    nB = target.size(0)\n",
        "    nA = num_anchors\n",
        "    nC = num_classes\n",
        "    anchor_step = len(anchors)/num_anchors\n",
        "    conf_mask  = torch.ones(nB, nA, nH, nW) * noobject_scale\n",
        "    coord_mask = torch.zeros(nB, nA, nH, nW)\n",
        "    cls_mask   = torch.zeros(nB, nA, nH, nW)\n",
        "    tx         = torch.zeros(nB, nA, nH, nW) \n",
        "    ty         = torch.zeros(nB, nA, nH, nW) \n",
        "    tw         = torch.zeros(nB, nA, nH, nW) \n",
        "    th         = torch.zeros(nB, nA, nH, nW) \n",
        "    tconf      = torch.zeros(nB, nA, nH, nW)\n",
        "    tcls       = torch.zeros(nB, nA, nH, nW) \n",
        "\n",
        "    nAnchors = nA*nH*nW\n",
        "    nPixels  = nH*nW\n",
        "    for b in xrange(nB):\n",
        "        cur_pred_boxes = pred_boxes[b*nAnchors:(b+1)*nAnchors].t()\n",
        "        cur_ious = torch.zeros(nAnchors)\n",
        "        for t in xrange(50):\n",
        "            if target[b][t*5+1] == 0:\n",
        "                break\n",
        "            gx = target[b][t*5+1]*nW\n",
        "            gy = target[b][t*5+2]*nH\n",
        "            gw = target[b][t*5+3]*nW\n",
        "            gh = target[b][t*5+4]*nH\n",
        "            cur_gt_boxes = torch.FloatTensor([gx,gy,gw,gh]).repeat(nAnchors,1).t()\n",
        "            cur_ious = torch.max(cur_ious, bbox_ious(cur_pred_boxes, cur_gt_boxes, x1y1x2y2=False))\n",
        "        conf_mask[b][cur_ious>sil_thresh] = 0\n",
        "    if seen < 12800:\n",
        "       if anchor_step == 4:\n",
        "           tx = torch.FloatTensor(anchors).view(nA, anchor_step).index_select(1, torch.LongTensor([2])).view(1,nA,1,1).repeat(nB,1,nH,nW)\n",
        "           ty = torch.FloatTensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([2])).view(1,nA,1,1).repeat(nB,1,nH,nW)\n",
        "       else:\n",
        "           tx.fill_(0.5)\n",
        "           ty.fill_(0.5)\n",
        "       tw.zero_()\n",
        "       th.zero_()\n",
        "       coord_mask.fill_(1)\n",
        "\n",
        "    nGT = 0\n",
        "    nCorrect = 0\n",
        "    for b in xrange(nB):\n",
        "        for t in xrange(50):\n",
        "            if target[b][t*5+1] == 0:\n",
        "                break\n",
        "            nGT = nGT + 1\n",
        "            best_iou = 0.0\n",
        "            best_n = -1\n",
        "            min_dist = 10000\n",
        "            gx = target[b][t*5+1] * nW\n",
        "            gy = target[b][t*5+2] * nH\n",
        "            gi = int(gx)\n",
        "            gj = int(gy)\n",
        "            gw = target[b][t*5+3]*nW\n",
        "            gh = target[b][t*5+4]*nH\n",
        "            gt_box = [0, 0, gw, gh]\n",
        "            for n in xrange(nA):\n",
        "                aw = anchors[anchor_step*n]\n",
        "                ah = anchors[anchor_step*n+1]\n",
        "                anchor_box = [0, 0, aw, ah]\n",
        "                iou  = bbox_iou(anchor_box, gt_box, x1y1x2y2=False)\n",
        "                if anchor_step == 4:\n",
        "                    ax = anchors[anchor_step*n+2]\n",
        "                    ay = anchors[anchor_step*n+3]\n",
        "                    dist = pow(((gi+ax) - gx), 2) + pow(((gj+ay) - gy), 2)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_n = n\n",
        "                elif anchor_step==4 and iou == best_iou and dist < min_dist:\n",
        "                    best_iou = iou\n",
        "                    best_n = n\n",
        "                    min_dist = dist\n",
        "\n",
        "            gt_box = [gx, gy, gw, gh]\n",
        "            pred_box = pred_boxes[b*nAnchors+best_n*nPixels+gj*nW+gi]\n",
        "\n",
        "            coord_mask[b][best_n][gj][gi] = 1\n",
        "            cls_mask[b][best_n][gj][gi] = 1\n",
        "            conf_mask[b][best_n][gj][gi] = object_scale\n",
        "            tx[b][best_n][gj][gi] = target[b][t*5+1] * nW - gi\n",
        "            ty[b][best_n][gj][gi] = target[b][t*5+2] * nH - gj\n",
        "            tw[b][best_n][gj][gi] = math.log(gw/anchors[anchor_step*best_n])\n",
        "            th[b][best_n][gj][gi] = math.log(gh/anchors[anchor_step*best_n+1])\n",
        "            iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False) # best_iou\n",
        "            tconf[b][best_n][gj][gi] = iou\n",
        "            tcls[b][best_n][gj][gi] = target[b][t*5]\n",
        "            if iou > 0.5:\n",
        "                nCorrect = nCorrect + 1\n",
        "\n",
        "    return nGT, nCorrect, coord_mask, conf_mask, cls_mask, tx, ty, tw, th, tconf, tcls\n",
        "\n",
        "class RegionLoss(nn.Module):\n",
        "    def __init__(self, num_classes=0, anchors=[], num_anchors=1):\n",
        "        super(RegionLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = num_anchors\n",
        "        self.anchor_step = int(len(anchors)/num_anchors)\n",
        "        self.coord_scale = 1\n",
        "        self.noobject_scale = 1\n",
        "        self.object_scale = 5\n",
        "        self.class_scale = 1\n",
        "        self.thresh = 0.6\n",
        "        self.seen = 0\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        #output : BxAs*(4+1+num_classes)*H*W\n",
        "        t0 = time.time()\n",
        "        nB = output.data.size(0)\n",
        "        nA = self.num_anchors\n",
        "        nC = self.num_classes\n",
        "        nH = output.data.size(2)\n",
        "        nW = output.data.size(3)\n",
        "\n",
        "        output   = output.view(nB, nA, (5+nC), nH, nW)\n",
        "        x    = F.sigmoid(output.index_select(2, Variable(torch.cuda.LongTensor([0]))).view(nB, nA, nH, nW))\n",
        "        y    = F.sigmoid(output.index_select(2, Variable(torch.cuda.LongTensor([1]))).view(nB, nA, nH, nW))\n",
        "        w    = output.index_select(2, Variable(torch.cuda.LongTensor([2]))).view(nB, nA, nH, nW)\n",
        "        h    = output.index_select(2, Variable(torch.cuda.LongTensor([3]))).view(nB, nA, nH, nW)\n",
        "        conf = F.sigmoid(output.index_select(2, Variable(torch.cuda.LongTensor([4]))).view(nB, nA, nH, nW))\n",
        "        cls  = output.index_select(2, Variable(torch.linspace(5,5+nC-1,nC).long().cuda()))\n",
        "        cls  = cls.view(nB*nA, nC, nH*nW).transpose(1,2).contiguous().view(nB*nA*nH*nW, nC)\n",
        "        t1 = time.time()\n",
        "\n",
        "        pred_boxes = torch.cuda.FloatTensor(4, nB*nA*nH*nW)\n",
        "        grid_x = torch.linspace(0, nW-1, nW).repeat(nH,1).repeat(nB*nA, 1, 1).view(nB*nA*nH*nW).cuda()\n",
        "        grid_y = torch.linspace(0, nH-1, nH).repeat(nW,1).t().repeat(nB*nA, 1, 1).view(nB*nA*nH*nW).cuda()\n",
        "        anchor_w = torch.Tensor(self.anchors).view(nA, int(self.anchor_step)).index_select(1, torch.LongTensor([0])).cuda()\n",
        "        anchor_h = torch.Tensor(self.anchors).view(nA, int(self.anchor_step)).index_select(1, torch.LongTensor([1])).cuda()\n",
        "        anchor_w = anchor_w.repeat(nB, 1).repeat(1, 1, nH*nW).view(nB*nA*nH*nW)\n",
        "        anchor_h = anchor_h.repeat(nB, 1).repeat(1, 1, nH*nW).view(nB*nA*nH*nW)\n",
        "        pred_boxes[0] = x.data + grid_x\n",
        "        pred_boxes[1] = y.data + grid_y\n",
        "        pred_boxes[2] = torch.exp(w.data) * anchor_w\n",
        "        pred_boxes[3] = torch.exp(h.data) * anchor_h\n",
        "        pred_boxes = convert2cpu(pred_boxes.transpose(0,1).contiguous().view(-1,4))\n",
        "        t2 = time.time()\n",
        "\n",
        "        nGT, nCorrect, coord_mask, conf_mask, cls_mask, tx, ty, tw, th, tconf,tcls = build_targets(pred_boxes, target.data, self.anchors, nA, nC, \\\n",
        "                                                               nH, nW, self.noobject_scale, self.object_scale, self.thresh, self.seen)\n",
        "        cls_mask = (cls_mask == 1)\n",
        "        nProposals = int((conf > 0.25).sum().data[0])\n",
        "\n",
        "        tx    = Variable(tx.cuda())\n",
        "        ty    = Variable(ty.cuda())\n",
        "        tw    = Variable(tw.cuda())\n",
        "        th    = Variable(th.cuda())\n",
        "        tconf = Variable(tconf.cuda())\n",
        "        tcls  = Variable(tcls.view(-1)[cls_mask].long().cuda())\n",
        "\n",
        "        coord_mask = Variable(coord_mask.cuda())\n",
        "        conf_mask  = Variable(conf_mask.cuda().sqrt())\n",
        "        cls_mask   = Variable(cls_mask.view(-1, 1).repeat(1,nC).cuda())\n",
        "        cls        = cls[cls_mask].view(-1, nC)  \n",
        "\n",
        "        t3 = time.time()\n",
        "\n",
        "        loss_x = self.coord_scale * nn.MSELoss(size_average=False)(x*coord_mask, tx*coord_mask)/2.0\n",
        "        loss_y = self.coord_scale * nn.MSELoss(size_average=False)(y*coord_mask, ty*coord_mask)/2.0\n",
        "        loss_w = self.coord_scale * nn.MSELoss(size_average=False)(w*coord_mask, tw*coord_mask)/2.0\n",
        "        loss_h = self.coord_scale * nn.MSELoss(size_average=False)(h*coord_mask, th*coord_mask)/2.0\n",
        "        loss_conf = nn.MSELoss(size_average=False)(conf*conf_mask, tconf*conf_mask)/2.0\n",
        "        loss_cls = self.class_scale * nn.CrossEntropyLoss(size_average=False)(cls, tcls)\n",
        "        loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls\n",
        "        t4 = time.time()\n",
        "        if False:\n",
        "            print('-----------------------------------')\n",
        "            print('        activation : %f' % (t1 - t0))\n",
        "            print(' create pred_boxes : %f' % (t2 - t1))\n",
        "            print('     build targets : %f' % (t3 - t2))\n",
        "            print('       create loss : %f' % (t4 - t3))\n",
        "            print('             total : %f' % (t4 - t0))\n",
        "        print('%d: nGT %d, recall %d, proposals %d, loss: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f' % (self.seen, nGT, nCorrect, nProposals, loss_x.data[0], loss_y.data[0], loss_w.data[0], loss_h.data[0], loss_conf.data[0], loss_cls.data[0], loss.data[0]))\n",
        "        return loss\n",
        "\n",
        "class MaxPoolStride1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MaxPoolStride1, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.pad(x, (0,1,0,1), mode='replicate'), 2, stride=1)\n",
        "        return x\n",
        "\n",
        "class Reorg(nn.Module):\n",
        "    def __init__(self, stride=2):\n",
        "        super(Reorg, self).__init__()\n",
        "        self.stride = stride\n",
        "    def forward(self, x):\n",
        "        stride = self.stride\n",
        "        assert(x.data.dim() == 4)\n",
        "        B = x.data.size(0)\n",
        "        C = x.data.size(1)\n",
        "        H = x.data.size(2)\n",
        "        W = x.data.size(3)\n",
        "        assert(H % stride == 0)\n",
        "        assert(W % stride == 0)\n",
        "        ws = stride\n",
        "        hs = stride\n",
        "        x = x.view((B, C, int(H/hs), hs, int(W/ws), ws)).transpose(3,4).contiguous()\n",
        "        x = x.view((B, C, int(H/hs*W/ws), hs*ws)).transpose(2,3).contiguous()\n",
        "        x = x.view((B, C, hs*ws, int(H/hs), int(W/ws))).transpose(1,2).contiguous()\n",
        "        x = x.view((B, hs*ws*C, int(H/hs), int(W/ws)))\n",
        "        return x\n",
        "\n",
        "class GlobalAvgPool2d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalAvgPool2d, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        N = x.data.size(0)\n",
        "        C = x.data.size(1)\n",
        "        H = x.data.size(2)\n",
        "        W = x.data.size(3)\n",
        "        x = F.avg_pool2d(x, (H, W))\n",
        "        x = x.view(N, C)\n",
        "        return x\n",
        "\n",
        "# for route and shortcut\n",
        "class EmptyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmptyModule, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "# support route shortcut and reorg\n",
        "class Darknet(nn.Module):\n",
        "\n",
        "    def __init__(self, cfgfile):\n",
        "        super(Darknet, self).__init__()\n",
        "        self.blocks = parse_cfg(cfgfile)\n",
        "        self.models = self.create_network(self.blocks) # merge conv, bn,leaky\n",
        "        self.loss = self.models[len(self.models)-1]\n",
        "\n",
        "        self.width = int(self.blocks[0]['width'])\n",
        "        self.height = int(self.blocks[0]['height'])\n",
        "\n",
        "        if self.blocks[(len(self.blocks)-1)]['type'] == 'region':\n",
        "            self.anchors = self.loss.anchors\n",
        "            self.num_anchors = self.loss.num_anchors\n",
        "            self.anchor_step = self.loss.anchor_step\n",
        "            self.num_classes = self.loss.num_classes\n",
        "\n",
        "        self.header = torch.IntTensor([0,0,0,0])\n",
        "        self.seen = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        ind = -2\n",
        "        self.loss = None\n",
        "        outputs = dict()\n",
        "        for block in self.blocks:\n",
        "            ind = ind + 1\n",
        "            #if ind > 0:\n",
        "            #    return x\n",
        "\n",
        "            if block['type'] == 'net':\n",
        "                continue\n",
        "            elif block['type'] == 'convolutional' or block['type'] == 'maxpool' or block['type'] == 'reorg' or block['type'] == 'avgpool' or block['type'] == 'softmax' or block['type'] == 'connected':\n",
        "                x = self.models[ind](x)\n",
        "                outputs[ind] = x\n",
        "\n",
        "            elif block['type'] == 'route':\n",
        "                layers = block['layers'].split(',')\n",
        "                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
        "                if len(layers) == 1:\n",
        "                    x = outputs[layers[0]]\n",
        "                    outputs[ind] = x\n",
        "                elif len(layers) == 2:\n",
        "                    x1 = outputs[layers[0]]\n",
        "                    x2 = outputs[layers[1]]\n",
        "                    x = torch.cat((x1,x2),1)\n",
        "                    outputs[ind] = x\n",
        "\n",
        "            elif block['type'] == 'shortcut':\n",
        "                from_layer = int(block['from'])\n",
        "                activation = block['activation']\n",
        "                from_layer = from_layer if from_layer > 0 else from_layer + ind\n",
        "                x1 = outputs[from_layer]\n",
        "                x2 = outputs[ind-1]\n",
        "                x  = x1 + x2\n",
        "                if activation == 'leaky':\n",
        "                    x = F.leaky_relu(x, 0.1, inplace=True)\n",
        "                elif activation == 'relu':\n",
        "                    x = F.relu(x, inplace=True)\n",
        "                outputs[ind] = x\n",
        "\n",
        "            elif block['type'] == 'region':\n",
        "                continue\n",
        "                if self.loss:\n",
        "                    self.loss = self.loss + self.models[ind](x)\n",
        "                else:\n",
        "                    self.loss = self.models[ind](x)\n",
        "                outputs[ind] = None\n",
        "\n",
        "            elif block['type'] == 'cost':\n",
        "                continue\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def print_network(self):\n",
        "        print_cfg(self.blocks)\n",
        "\n",
        "    def create_network(self, blocks):\n",
        "        models = nn.ModuleList()\n",
        "    \n",
        "        prev_filters = 3\n",
        "        out_filters =[]\n",
        "        conv_id = 0\n",
        "        for block in blocks:\n",
        "            if block['type'] == 'net':\n",
        "                prev_filters = int(block['channels'])\n",
        "                continue\n",
        "            elif block['type'] == 'convolutional':\n",
        "                conv_id = conv_id + 1\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                filters = int(block['filters'])\n",
        "                kernel_size = int(block['size'])\n",
        "                stride = int(block['stride'])\n",
        "                is_pad = int(block['pad'])\n",
        "                pad    = int((kernel_size-1)/2) if is_pad else 0\n",
        "                activation = block['activation']\n",
        "                model = nn.Sequential()\n",
        "                if batch_normalize:\n",
        "                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=False))\n",
        "                    model.add_module('bn{0}'.format(conv_id), nn.BatchNorm2d(filters))\n",
        "                    #model.add_module('bn{0}'.format(conv_id), BN2d(filters))\n",
        "                else:\n",
        "                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad))\n",
        "                if activation == 'leaky':\n",
        "                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\n",
        "                elif activation == 'relu':\n",
        "                    model.add_module('relu{0}'.format(conv_id), nn.ReLU(inplace=True))\n",
        "                prev_filters = filters\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'maxpool':\n",
        "                pool_size = int(block['size'])\n",
        "                stride = int(block['stride'])\n",
        "                if stride > 1:\n",
        "                    model = nn.MaxPool2d(pool_size, stride)\n",
        "                else:\n",
        "                    model = MaxPoolStride1()\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'avgpool':\n",
        "                model = GlobalAvgPool2d()\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'softmax':\n",
        "                model = nn.Softmax()\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'cost':\n",
        "                if block['_type'] == 'sse':\n",
        "                    model = nn.MSELoss(size_average=True)\n",
        "                elif block['_type'] == 'L1':\n",
        "                    model = nn.L1Loss(size_average=True)\n",
        "                elif block['_type'] == 'smooth':\n",
        "                    model = nn.SmoothL1Loss(size_average=True)\n",
        "                out_filters.append(1)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'reorg':\n",
        "                stride = int(block['stride'])\n",
        "                prev_filters = stride * stride * prev_filters\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(Reorg(stride))\n",
        "            elif block['type'] == 'route':\n",
        "                layers = block['layers'].split(',')\n",
        "                ind = len(models)\n",
        "                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
        "                if len(layers) == 1:\n",
        "                    prev_filters = out_filters[layers[0]]\n",
        "                elif len(layers) == 2:\n",
        "                    assert(layers[0] == ind - 1)\n",
        "                    prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(EmptyModule())\n",
        "            elif block['type'] == 'shortcut':\n",
        "                ind = len(models)\n",
        "                prev_filters = out_filters[ind-1]\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(EmptyModule())\n",
        "            elif block['type'] == 'connected':\n",
        "                filters = int(block['output'])\n",
        "                if block['activation'] == 'linear':\n",
        "                    model = nn.Linear(prev_filters, filters)\n",
        "                elif block['activation'] == 'leaky':\n",
        "                    model = nn.Sequential(\n",
        "                               nn.Linear(prev_filters, filters),\n",
        "                               nn.LeakyReLU(0.1, inplace=True))\n",
        "                elif block['activation'] == 'relu':\n",
        "                    model = nn.Sequential(\n",
        "                               nn.Linear(prev_filters, filters),\n",
        "                               nn.ReLU(inplace=True))\n",
        "                prev_filters = filters\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'region':\n",
        "                loss = RegionLoss()\n",
        "                anchors = block['anchors'].split(',')\n",
        "                loss.anchors = [float(i) for i in anchors]\n",
        "                loss.num_classes = int(block['classes'])\n",
        "                loss.num_anchors = int(block['num'])\n",
        "                loss.anchor_step = len(loss.anchors)/loss.num_anchors\n",
        "                loss.object_scale = float(block['object_scale'])\n",
        "                loss.noobject_scale = float(block['noobject_scale'])\n",
        "                loss.class_scale = float(block['class_scale'])\n",
        "                loss.coord_scale = float(block['coord_scale'])\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(loss)\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "    \n",
        "        return models\n",
        "\n",
        "    def load_weights(self, weightfile):\n",
        "        with open(weightfile, mode='rb') as f:\n",
        "            major = np.fromfile(f, dtype=np.int32, count=1)\n",
        "            minor = np.fromfile(f, dtype=np.int32, count=1)\n",
        "            np.fromfile(f, dtype=np.int32, count=1)  # revision\n",
        "            if major * 10 + minor >= 2 and major < 1000 and minor < 1000:\n",
        "                np.fromfile(f, dtype=np.int64, count=1)  # seen\n",
        "            else:\n",
        "                np.fromfile(f, dtype=np.int32, count=1)  # seen\n",
        "\n",
        "            ind = -2\n",
        "            for block in self.blocks:\n",
        "                if ind >= len(self.models):\n",
        "                    break\n",
        "                ind = ind + 1\n",
        "                if block['type'] == 'net':\n",
        "                    continue\n",
        "                elif block['type'] == 'convolutional':\n",
        "                    model = self.models[ind]\n",
        "                    batch_normalize = int(block['batch_normalize'])\n",
        "                    if batch_normalize:\n",
        "                        start = load_conv_bn(f, model[0], model[1])\n",
        "                    else:\n",
        "                        start = load_conv(f, model[0])\n",
        "                elif block['type'] == 'connected':\n",
        "                    model = self.models[ind]\n",
        "                    if block['activation'] != 'linear':\n",
        "                        start = load_fc(f, model[0])\n",
        "                    else:\n",
        "                        start = load_fc(f, model)\n",
        "                elif block['type'] == 'maxpool':\n",
        "                    pass\n",
        "                elif block['type'] == 'reorg':\n",
        "                    pass\n",
        "                elif block['type'] == 'route':\n",
        "                    pass\n",
        "                elif block['type'] == 'shortcut':\n",
        "                    pass\n",
        "                elif block['type'] == 'region':\n",
        "                    pass\n",
        "                elif block['type'] == 'avgpool':\n",
        "                    pass\n",
        "                elif block['type'] == 'softmax':\n",
        "                    pass\n",
        "                elif block['type'] == 'cost':\n",
        "                    pass\n",
        "                else:\n",
        "                    print('unknown type %s' % (block['type']))\n",
        "\n",
        "    def load_weights_old(self, weightfile):\n",
        "        fp          = open(weightfile, 'rb')\n",
        "        header      = np.fromfile(fp, count=4, dtype=np.int32)\n",
        "        self.header = torch.from_numpy(header)\n",
        "        self.seen   = self.header[3]\n",
        "        buf         = np.fromfile(fp, dtype = np.float32)\n",
        "        fp.close()\n",
        "\n",
        "        start = 0\n",
        "        ind = -2\n",
        "        for block_i, block in enumerate(self.blocks):\n",
        "            print ('')\n",
        "            print (' ----------------- block : ', block_i, '(start:',start,')')\n",
        "            print (' || --------------> block : ', block)\n",
        "            if start >= buf.size:\n",
        "                break\n",
        "            ind = ind + 1\n",
        "            print (' || ---------------> self.models[ind] : ', self.models[ind])\n",
        "            if block['type'] == 'net':\n",
        "                continue\n",
        "            elif block['type'] == 'convolutional':\n",
        "                try:\n",
        "                    model           = self.models[ind]\n",
        "                    batch_normalize = int(block['batch_normalize'])\n",
        "                    if batch_normalize:\n",
        "                        start = load_conv_bn(buf, start, model[0], model[1])\n",
        "                    else:\n",
        "                        start = load_conv(buf, start, model[0])\n",
        "                except:\n",
        "                    print (' - [Err] Block :', block_i)\n",
        "                    traceback.print_exc()\n",
        "                    import sys; sys.exit(1)\n",
        "            elif block['type'] == 'connected':\n",
        "                model = self.models[ind]\n",
        "                if block['activation'] != 'linear':\n",
        "                    start = load_fc(buf, start, model[0])\n",
        "                else:\n",
        "                    start = load_fc(buf, start, model)\n",
        "            elif block['type'] == 'maxpool':\n",
        "                pass\n",
        "            elif block['type'] == 'reorg':\n",
        "                pass\n",
        "            elif block['type'] == 'route':\n",
        "                pass\n",
        "            elif block['type'] == 'shortcut':\n",
        "                pass\n",
        "            elif block['type'] == 'region':\n",
        "                pass\n",
        "            elif block['type'] == 'avgpool':\n",
        "                pass\n",
        "            elif block['type'] == 'softmax':\n",
        "                pass\n",
        "            elif block['type'] == 'cost':\n",
        "                pass\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "\n",
        "    def save_weights(self, outfile, cutoff=0):\n",
        "        if cutoff <= 0:\n",
        "            cutoff = len(self.blocks)-1\n",
        "\n",
        "        fp = open(outfile, 'wb')\n",
        "        self.header[3] = self.seen\n",
        "        header = self.header\n",
        "        header.numpy().tofile(fp)\n",
        "\n",
        "        ind = -1\n",
        "        for blockId in range(1, cutoff+1):\n",
        "            ind = ind + 1\n",
        "            block = self.blocks[blockId]\n",
        "            if block['type'] == 'convolutional':\n",
        "                model = self.models[ind]\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                if batch_normalize:\n",
        "                    save_conv_bn(fp, model[0], model[1])\n",
        "                else:\n",
        "                    save_conv(fp, model[0])\n",
        "            elif block['type'] == 'connected':\n",
        "                model = self.models[ind]\n",
        "                if block['activation'] != 'linear':\n",
        "                    save_fc(fc, model)\n",
        "                else:\n",
        "                    save_fc(fc, model[0])\n",
        "            elif block['type'] == 'maxpool':\n",
        "                pass\n",
        "            elif block['type'] == 'reorg':\n",
        "                pass\n",
        "            elif block['type'] == 'route':\n",
        "                pass\n",
        "            elif block['type'] == 'shortcut':\n",
        "                pass\n",
        "            elif block['type'] == 'region':\n",
        "                pass\n",
        "            elif block['type'] == 'avgpool':\n",
        "                pass\n",
        "            elif block['type'] == 'softmax':\n",
        "                pass\n",
        "            elif block['type'] == 'cost':\n",
        "                pass\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "        fp.close()\n",
        "\n",
        "def getYOLOv2(cfgfile, weightfile):\n",
        "    model = Darknet(cfgfile)\n",
        "    model.load_weights(weightfile)\n",
        "    if USE_GPU:\n",
        "        model.cuda()\n",
        "    return model\n",
        "\n",
        "def testYOLOv2():\n",
        "\n",
        "    cfgfile    = 'data/cfg/github_pjreddie/yolov2-voc.cfg'\n",
        "    weightfile = 'data/weights/github_pjreddie/yolov2-voc.weights'\n",
        "    model      = getYOLOv2(cfgfile, weightfile) \n",
        "    print (' - 1. Model is loaded!')\n",
        "\n",
        "    imgdir      = 'data/dataset/yolo_samples'\n",
        "    namesfile   = 'data/dataset/voc.names'\n",
        "    class_names = load_class_names(namesfile)\n",
        "    for each in ['dog.jpg', 'eagle.jpg',  'giraffe.jpg',  'horses.jpg',  'person.jpg',  'scream.jpg']:\n",
        "        try:\n",
        "            print ('')\n",
        "            imgfile = os.path.join(imgdir, each)        \n",
        "            img     = Image.open(imgfile).convert('RGB')\n",
        "            sized   = img.resize((model.width, model.height))\n",
        "\n",
        "            start  = time.time()\n",
        "            boxes  = do_detect(model, sized, 0.5, 0.4, USE_GPU)\n",
        "            finish = time.time()\n",
        "            print('%s: Predicted in %f seconds.' % (imgfile, (finish-start)))\n",
        "            plot_boxes(img, boxes, os.path.join(imgdir, '_' + each), class_names)\n",
        "        except:\n",
        "            traceback.print_exc()\n",
        "            pass\n",
        "\n",
        "class TinyYoloNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TinyYoloNet, self).__init__()\n",
        "        self.seen = 0\n",
        "        self.num_classes = 20\n",
        "        self.anchors = [1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52]\n",
        "        self.num_anchors = len(self.anchors)/2\n",
        "        num_output = (5+self.num_classes)*self.num_anchors\n",
        "        self.width = 160\n",
        "        self.height = 160\n",
        "\n",
        "        self.loss = RegionLoss(self.num_classes, self.anchors, self.num_anchors)\n",
        "        self.cnn = nn.Sequential(OrderedDict([\n",
        "            # conv1\n",
        "            ('conv1', nn.Conv2d( 3, 16, 3, 1, 1, bias=False)),\n",
        "            ('bn1', nn.BatchNorm2d(16)),\n",
        "            ('leaky1', nn.LeakyReLU(0.1, inplace=True)),\n",
        "            ('pool1', nn.MaxPool2d(2, 2)),\n",
        "\n",
        "            # conv2\n",
        "            ('conv2', nn.Conv2d(16, 32, 3, 1, 1, bias=False)),\n",
        "            ('bn2', nn.BatchNorm2d(32)),\n",
        "            ('leaky2', nn.LeakyReLU(0.1, inplace=True)),\n",
        "            ('pool2', nn.MaxPool2d(2, 2)),\n",
        "\n",
        "            # conv3\n",
        "            ('conv3', nn.Conv2d(32, 64, 3, 1, 1, bias=False)),\n",
        "            ('bn3', nn.BatchNorm2d(64)),\n",
        "            ('leaky3', nn.LeakyReLU(0.1, inplace=True)),\n",
        "            ('pool3', nn.MaxPool2d(2, 2)),\n",
        "\n",
        "            # conv4\n",
        "            ('conv4', nn.Conv2d(64, 128, 3, 1, 1, bias=False)),\n",
        "            ('bn4', nn.BatchNorm2d(128)),\n",
        "            ('leaky4', nn.LeakyReLU(0.1, inplace=True)),\n",
        "            ('pool4', nn.MaxPool2d(2, 2)),\n",
        "\n",
        "            # conv5\n",
        "            ('conv5', nn.Conv2d(128, 256, 3, 1, 1, bias=False)),\n",
        "            ('bn5', nn.BatchNorm2d(256)),\n",
        "            ('leaky5', nn.LeakyReLU(0.1, inplace=True)),\n",
        "            ('pool5', nn.MaxPool2d(2, 2)),\n",
        "\n",
        "            # conv6\n",
        "            ('conv6', nn.Conv2d(256, 512, 3, 1, 1, bias=False)),\n",
        "            ('bn6', nn.BatchNorm2d(512)),\n",
        "            ('leaky6', nn.LeakyReLU(0.1, inplace=True)),\n",
        "            ('pool6', MaxPoolStride1()),\n",
        "\n",
        "            # conv7\n",
        "            ('conv7', nn.Conv2d(512, 1024, 3, 1, 1, bias=False)),\n",
        "            ('bn7', nn.BatchNorm2d(1024)),\n",
        "            ('leaky7', nn.LeakyReLU(0.1, inplace=True)),\n",
        "\n",
        "            # conv8\n",
        "            ('conv8', nn.Conv2d(1024, 1024, 3, 1, 1, bias=False)),\n",
        "            ('bn8', nn.BatchNorm2d(1024)),\n",
        "            ('leaky8', nn.LeakyReLU(0.1, inplace=True)),\n",
        "\n",
        "            # output\n",
        "            ('output', nn.Conv2d(1024, num_output, 1, 1, 0)),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        return x\n",
        "\n",
        "    def print_network(self):\n",
        "        print(self)\n",
        "\n",
        "    def load_weights(self, path):\n",
        "        #buf = np.fromfile('tiny-yolo-voc.weights', dtype = np.float32)\n",
        "        buf = np.fromfile(path, dtype = np.float32)\n",
        "        start = 4\n",
        "        \n",
        "        start = load_conv_bn(buf, start, self.cnn[0], self.cnn[1])\n",
        "        start = load_conv_bn(buf, start, self.cnn[4], self.cnn[5])\n",
        "        start = load_conv_bn(buf, start, self.cnn[8], self.cnn[9])\n",
        "        start = load_conv_bn(buf, start, self.cnn[12], self.cnn[13])\n",
        "        start = load_conv_bn(buf, start, self.cnn[16], self.cnn[17])\n",
        "        start = load_conv_bn(buf, start, self.cnn[20], self.cnn[21])\n",
        "        \n",
        "        start = load_conv_bn(buf, start, self.cnn[24], self.cnn[25])\n",
        "        start = load_conv_bn(buf, start, self.cnn[27], self.cnn[28])\n",
        "        start = load_conv(buf, start, self.cnn[30])\n",
        "\n",
        "## --------------------------------------- YOLOV1 --------------------------------------- ##\n",
        "\n",
        "\n",
        "def getYOLOv1Self(name=''):\n",
        "\n",
        "    cfg = {\n",
        "        'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "        'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "        'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "        'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "    }\n",
        "\n",
        "    if name != '':\n",
        "        myYOLO            = YOLOv1Self(name, cfg['D'], batch_norm=True)\n",
        "        VGG               = models.vgg16_bn(pretrained=True)\n",
        "        state_dict_VGG    = VGG.state_dict()\n",
        "        state_dict_myYOLO = myYOLO.state_dict()\n",
        "        \n",
        "        for k in state_dict_VGG.keys():\n",
        "            if k in state_dict_myYOLO.keys() and k.startswith('features'):\n",
        "                state_dict_myYOLO[k] = state_dict_VGG[k]\n",
        "        myYOLO.load_state_dict(state_dict_myYOLO)\n",
        "        return myYOLO\n",
        "\n",
        "    else:\n",
        "        print (' - Pass a name for your model')\n",
        "        sys.exit(1)\n",
        "\n",
        "class YOLOv1Self(nn.Module):\n",
        "\n",
        "    def __init__(self, name, cfg, batch_norm, image_size=448):\n",
        "        super(YOLOv1Self, self).__init__()\n",
        "        self.name       = name\n",
        "        self.features   = self.getFeatureLayers(cfg, batch_norm)\n",
        "        self.linear1    = MaskedLinear(512 * 7 * 7, 4096)\n",
        "        self.linear2    = MaskedLinear(4096, 1470)\n",
        "        self.classifier = nn.Sequential( # add the regression part to the features\n",
        "            # nn.Linear(512 * 7 * 7, 4096),\n",
        "            self.linear1,\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            # nn.Linear(4096, 1470),\n",
        "            self.linear2,\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = x.view(-1,7,7,30)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def getFeatureLayers(self, cfg, batch_norm=False):\n",
        "        if (1):\n",
        "            params_in_channels  = 3\n",
        "            params_conv_stride  = 1\n",
        "            params_conv_size    = 3 \n",
        "            params_first_flag   = True\n",
        "            params_pool_stride  = 2\n",
        "            params_pool_kernel  = 2\n",
        "\n",
        "        layers = []\n",
        "        for item in cfg:\n",
        "            params_conv_stride = 1\n",
        "            if (item == 64 and params_first_flag):\n",
        "                params_conv_stride = 2\n",
        "                params_first_flag  = False\n",
        "\n",
        "            if item == 'M': # max-pooling\n",
        "                layers += [nn.MaxPool2d(kernel_size=params_pool_kernel, stride=params_pool_stride)]\n",
        "            else:\n",
        "                params_kernels = item\n",
        "                conv2d = nn.Conv2d(params_in_channels, params_kernels, kernel_size=params_conv_size, stride=params_conv_stride, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [conv2d, nn.BatchNorm2d(item), nn.ReLU(inplace=True)]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                params_in_channels = item\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def set_masks(self, masks):\n",
        "        self.linear1.set_mask(masks[0])\n",
        "        self.linear2.set_mask(masks[1])\n",
        "\n",
        "def testYOLOv1():\n",
        "    if (0):\n",
        "        net = getYOLOv1Self()\n",
        "        img = torch.rand(1,3,448,448)\n",
        "        img = Variable(img)\n",
        "        output = net(img)\n",
        "        print(output.size())\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # testYOLOv1()\n",
        "#     # testYOLOv2()\n",
        "#     # blocks = parse_cfg('/home/strider/Work/Netherlands/TUDelft/1_Courses/Sem2/DeepLearning/Project/repo1/data/cfg/github_pjreddie/yolov2-voc.cfg',1)\n",
        "#     blocks = parse_cfg('/home/strider/Work/Netherlands/TUDelft/1_Courses/Sem2/DeepLearning/Project/repo1/data/cfg/github_pjreddie/yolov1.cfg',1)\n",
        "#     model  = create_network(self.blocks) # merge conv, bn,leaky\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "URLs\n",
        "    - YOLOv1 \n",
        "        - https://pjreddie.com/darknet/yolov1/\n",
        "            - wget http://pjreddie.com/media/files/yolov1/yolov1.weights (~800MB) [trained on 2007 train/val+ 2012 train/val]\n",
        "            - https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov1.cfg (output = 1715 = 7x7x(3x5 + 20) ) \n",
        "                - Locally Connected FC (https://discuss.pytorch.org/t/how-does-pytorch-implement-local-convolutional-layer-local-connected-layer/4316)\n",
        "                    - https://github.com/pjreddie/darknet/issues/876\n",
        "                    - https://github.com/pytorch/pytorch/issues/499\n",
        "                    - https://github.com/pytorch/pytorch/compare/master...1zb:conv-local\n",
        "                    - Theory : https://www.cs.toronto.edu/~jlucas/teaching/csc411/lectures/lec11_handout.pdf\n",
        "                - Locally Connected FC (https://www.tensorflow.org/api_docs/python/tf/keras/layers/LocallyConnected2D)\n",
        "    - YOLOv2    \n",
        "        - https://pjreddie.com/darknet/yolov2/\n",
        "            - https://github.com/pjreddie/darknet/blob/master/cfg/yolov2-voc.cfg [416 x 416]\n",
        "            - wget https://pjreddie.com/media/files/yolov2-voc.weights (~MB) [trained on 2007 train/val+ 2012 train/val]\n",
        "        - On other gthubs\n",
        "            - wget http://pjreddie.com/media/files/yolo.weights\n",
        "            - wget https://pjreddie.com/media/files/yolo-voc.weights\n",
        "    - Dataset\n",
        "        - <> \n",
        "\n",
        "Results\n",
        "    - YOLOv1 (inside YOLO paper)\n",
        "        - (2007 + 2012) = 63.4 mAP\n",
        "        - (2007 + 2012) = 66.4 mAP (VGG-16)\n",
        "    - repo1 (https://github.com/yxlijun/tensorflow-yolov1)\n",
        "        - (2007 + 2012) = 65.3 mAP (VGG-16)\n",
        "        - (2007 + 2012) = 66.12 mAP (VGG-19)\n",
        "        - (2007 + 2012) = 65.23 mAP (Resnet)\n",
        "\n",
        "Pre-trained Weights\n",
        "    - YOLOv1\n",
        "        - repo1 : https://github.com/dshahrokhian/YOLO_tensorflow\n",
        "            - YOLO_small.ckpt\n",
        "        - repo1 : https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html\n",
        "            - convert from pjreddie --> tensorflow --> convert to pytorch\n",
        "\n",
        "Converter\n",
        "    - https://github.com/microsoft/MMdnn\n",
        "    - https://github.com/marvis/pytorch-caffe-darknet-convert\n",
        "    - https://github.com/AceCoooool/YOLO-pytorch/blob/master/tools/yad2t.py\n",
        "    - https://github.com/thtrieu/darkflow.git\n",
        "        - git clone https://github.com/thtrieu/darkflow.git\n",
        "        - cd darkflow\n",
        "        - pip install -e .\n",
        "        - wget http://pjreddie.com/media/files/yolov1/yolov1.weights\n",
        "        - flow --model cfg/v1.1/yolov1.cfg --load ../../repo1/data/weights/github_pjreddie/yolov1.weights --savepb\n",
        "        - Colab\n",
        "            - # ! git clone https://github.com/thtrieu/darkflow.git\n",
        "                # ! cd darkflow && pip install -e .\n",
        "                # ! wget http://pjreddie.com/media/files/yolov1/yolov1.weights\n",
        "                # ! flow -h\n",
        "                # ! ls -l\n",
        "                # ! flow --model darkflow/cfg/v1.1/yolov1.cfg --load yolov1.weights --savepb\n",
        "\n",
        "Random\n",
        "    - https://github.com/happyjin/pytorch-YOLO/blob/master/network.py\n",
        "    - https://github.com/kevin970401/pytorch-YOLO-v1/blob/master/models/yolo.py\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "We train the network for about \n",
        " - 135 epochs on the train-ing and validation data sets from PASCAL VOC 2007 and 2012. \n",
        " - When testing on 2012 we also include the VOC 2007 test data for training. \n",
        " - Throughout training we use a \n",
        "    - batch size of 64, a momentum of 0.9 and a decay of 0.0005. \n",
        " - Our learning rate schedule is as follows: \n",
        "    - For the first epochs we slowly raise the learning rate from 10−3 to 10−2. \n",
        "    - If we start at a high learning rate our model often diverges due to unstable gradients. \n",
        "    - We continue training with \n",
        "        - 10−2 for 75 epochs\n",
        "        - then 10−3 for 30 epochs\n",
        "        - and finally 10−4 for 30 epochs\n",
        "\"\"\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe train the network for about \\n - 135 epochs on the train-ing and validation data sets from PASCAL VOC 2007 and 2012. \\n - When testing on 2012 we also include the VOC 2007 test data for training. \\n - Throughout training we use a \\n    - batch size of 64, a momentum of 0.9 and a decay of 0.0005. \\n - Our learning rate schedule is as follows: \\n    - For the first epochs we slowly raise the learning rate from 10−3 to 10−2. \\n    - If we start at a high learning rate our model often diverges due to unstable gradients. \\n    - We continue training with \\n        - 10−2 for 75 epochs\\n        - then 10−3 for 30 epochs\\n        - and finally 10−4 for 30 epochs\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2man52H0NLYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train\n",
        "import tqdm\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# # import dataloader\n",
        "# from nets2_utils import *\n",
        "# from nets import parse_cfg\n",
        "# from nets import Darknet\n",
        "# from nets import RegionLoss\n",
        "# from nets import TinyYoloNet\n",
        "\n",
        "## --------------------------------------- YOLOV2 --------------------------------------- ##\n",
        "class YOLOv2Train():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model       = ''\n",
        "        self.optimizer   = ''\n",
        "\n",
        "    def train(self, datacfg, cfgfile, weightfile):\n",
        "        data_options  = read_data_cfg(datacfg)\n",
        "        net_options   = parse_cfg(cfgfile)[0]\n",
        "\n",
        "        trainlist     = data_options['train']\n",
        "        testlist      = data_options['valid']\n",
        "        backupdir     = data_options['backup']\n",
        "        nsamples      = file_lines(trainlist)\n",
        "        gpus          = \"1\"\n",
        "        ngpus         = 1\n",
        "        num_workers   = 4\n",
        "\n",
        "        batch_size    = int(net_options['batch'])\n",
        "        max_batches   = int(net_options['max_batches'])\n",
        "        learning_rate = float(net_options['learning_rate'])\n",
        "        momentum      = float(net_options['momentum'])\n",
        "        decay         = float(net_options['decay'])\n",
        "        steps         = [float(step) for step in net_options['steps'].split(',')]\n",
        "        scales        = [float(scale) for scale in net_options['scales'].split(',')]\n",
        "\n",
        "        #Train parameters\n",
        "        max_epochs    =int(max_batches*batch_size/nsamples+1)\n",
        "        use_cuda      = True\n",
        "        seed          = int(time.time())\n",
        "        eps           = 1e-5\n",
        "        save_interval = 10  # epoches\n",
        "        dot_interval  = 70  # batches\n",
        "\n",
        "        # Test parameters\n",
        "        conf_thresh   = 0.25\n",
        "        nms_thresh    = 0.4\n",
        "        iou_thresh    = 0.5\n",
        "\n",
        "        if not os.path.exists(backupdir):\n",
        "            os.mkdir(backupdir)\n",
        "\n",
        "        ###############\n",
        "        torch.manual_seed(seed)\n",
        "        if use_cuda:\n",
        "            os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
        "            torch.cuda.manual_seed(seed)\n",
        "\n",
        "        model       = Darknet(cfgfile)\n",
        "        region_loss = model.loss\n",
        "\n",
        "        model.load_weights(weightfile)\n",
        "        model.print_network()\n",
        "\n",
        "        region_loss.seen  = model.seen\n",
        "        processed_batches = model.seen/batch_size\n",
        "\n",
        "        init_width        = model.width\n",
        "        init_height       = model.height\n",
        "        init_epoch        = model.seen/nsamples \n",
        "\n",
        "        kwargs = {'num_workers': num_workers, 'pin_memory': True} if use_cuda else {}\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "#             dataloader.VOCDatasetv2(testlist, shape=(init_width, init_height),\n",
        "              VOCDatasetv2(testlist, shape=(init_width, init_height),\n",
        "                        shuffle=False,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                        ]), train=False),\n",
        "            batch_size=batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "        if use_cuda:\n",
        "            if ngpus > 1:\n",
        "                model = torch.nn.DataParallel(model).cuda()\n",
        "            else:\n",
        "                model = model.cuda()\n",
        "\n",
        "        params_dict = dict(model.named_parameters())\n",
        "        params = []\n",
        "        for key, value in params_dict.items():\n",
        "            if key.find('.bn') >= 0 or key.find('.bias') >= 0:\n",
        "                params += [{'params': [value], 'weight_decay': 0.0}]\n",
        "            else:\n",
        "                params += [{'params': [value], 'weight_decay': decay*batch_size}]\n",
        "        optimizer = optim.SGD(model.parameters(), \n",
        "                                lr=learning_rate/batch_size, momentum=momentum,\n",
        "                                dampening=0, weight_decay=decay*batch_size)\n",
        "        \n",
        "        for epoch in range(int(init_epoch), max_epochs): \n",
        "            ## ----------------------- TRAIN ------------------------\n",
        "#             global processed_batches\n",
        "            t0 = time.time()\n",
        "            if ngpus > 1:\n",
        "                cur_model = model.module\n",
        "            else:\n",
        "                cur_model = model\n",
        "            \n",
        "            train_loader = torch.utils.data.DataLoader(\n",
        "#                 dataloader.VOCDatasetv2(trainlist, shape=(init_width, init_height),\n",
        "                VOCDatasetv2(trainlist, shape=(init_width, init_height),\n",
        "                            shuffle=True,\n",
        "                            transform=transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                            ]),\n",
        "                            train=True,\n",
        "                            seen=cur_model.seen,\n",
        "                            batch_size=batch_size),\n",
        "                batch_size=batch_size, shuffle=False, **kwargs)               \n",
        "\n",
        "            lr = self.adjust_learning_rate(optimizer, processed_batches, learning_rate, steps, scales, batch_size)\n",
        "            logging('epoch %d, processed %d samples, lr %f' % (epoch, epoch * len(train_loader.dataset), lr))\n",
        "            model.train()\n",
        "            t1 = time.time()\n",
        "            avg_time = torch.zeros(9)\n",
        "            for batch_idx, (data, target) in enumerate(train_loader):\n",
        "                t2 = time.time()\n",
        "                self.adjust_learning_rate(optimizer, processed_batches, learning_rate, steps, scales, batch_size)\n",
        "                processed_batches = processed_batches + 1\n",
        "                #if (batch_idx+1) % dot_interval == 0:\n",
        "                #    sys.stdout.write('.')\n",
        "\n",
        "                if use_cuda:\n",
        "                    data = data.cuda()\n",
        "                    #target= target.cuda()\n",
        "                t3 = time.time()\n",
        "                data, target = Variable(data), Variable(target)\n",
        "                t4 = time.time()\n",
        "                optimizer.zero_grad()\n",
        "                t5 = time.time()\n",
        "                output = model(data)\n",
        "                t6 = time.time()\n",
        "                region_loss.seen = region_loss.seen + data.data.size(0)\n",
        "                loss = region_loss(output, target)\n",
        "                t7 = time.time()\n",
        "                loss.backward()\n",
        "                t8 = time.time()\n",
        "                optimizer.step()\n",
        "                t9 = time.time()\n",
        "                if False and batch_idx > 1:\n",
        "                    avg_time[0] = avg_time[0] + (t2-t1)\n",
        "                    avg_time[1] = avg_time[1] + (t3-t2)\n",
        "                    avg_time[2] = avg_time[2] + (t4-t3)\n",
        "                    avg_time[3] = avg_time[3] + (t5-t4)\n",
        "                    avg_time[4] = avg_time[4] + (t6-t5)\n",
        "                    avg_time[5] = avg_time[5] + (t7-t6)\n",
        "                    avg_time[6] = avg_time[6] + (t8-t7)\n",
        "                    avg_time[7] = avg_time[7] + (t9-t8)\n",
        "                    avg_time[8] = avg_time[8] + (t9-t1)\n",
        "                    print('-------------------------------')\n",
        "                    print('       load data : %f' % (avg_time[0]/(batch_idx)))\n",
        "                    print('     cpu to cuda : %f' % (avg_time[1]/(batch_idx)))\n",
        "                    print('cuda to variable : %f' % (avg_time[2]/(batch_idx)))\n",
        "                    print('       zero_grad : %f' % (avg_time[3]/(batch_idx)))\n",
        "                    print(' forward feature : %f' % (avg_time[4]/(batch_idx)))\n",
        "                    print('    forward loss : %f' % (avg_time[5]/(batch_idx)))\n",
        "                    print('        backward : %f' % (avg_time[6]/(batch_idx)))\n",
        "                    print('            step : %f' % (avg_time[7]/(batch_idx)))\n",
        "                    print('           total : %f' % (avg_time[8]/(batch_idx)))\n",
        "                t1 = time.time()\n",
        "            print('')\n",
        "            t1 = time.time()\n",
        "            logging('training with %f samples/s' % (len(train_loader.dataset)/(t1-t0)))\n",
        "            if (epoch+1) % save_interval == 0:\n",
        "                logging('save weights to %s/%06d.weights' % (backupdir, epoch+1))\n",
        "                cur_model.seen = (epoch + 1) * len(train_loader.dataset)\n",
        "                cur_model.save_weights('%s/%06d.weights' % (backupdir, epoch+1))\n",
        "\n",
        "            ## ----------------------- TEST ------------------------\n",
        "            self.test(epoch)\n",
        "        # end for epoch\n",
        "\n",
        "    def adjust_learning_rate(self, optimizer, batch, learning_rate, steps, scales, batch_size):\n",
        "        \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "        lr = learning_rate\n",
        "        for i in range(len(steps)):\n",
        "            scale = scales[i] if i < len(scales) else 1\n",
        "            if batch >= steps[i]:\n",
        "                lr = lr * scale\n",
        "                if batch == steps[i]:\n",
        "                    break\n",
        "            else:\n",
        "                break\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr/batch_size\n",
        "        return lr\n",
        "\n",
        "    def test(self, epoch):\n",
        "        def truths_length(truths):\n",
        "            for i in range(50):\n",
        "                if truths[i][1] == 0:\n",
        "                    return i\n",
        "\n",
        "        model.eval()\n",
        "        if ngpus > 1:\n",
        "            cur_model = model.module\n",
        "        else:\n",
        "            cur_model = model\n",
        "        num_classes = cur_model.num_classes\n",
        "        anchors     = cur_model.anchors\n",
        "        num_anchors = cur_model.num_anchors\n",
        "        total       = 0.0\n",
        "        proposals   = 0.0\n",
        "        correct     = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            if use_cuda:\n",
        "                data = data.cuda()\n",
        "            data = Variable(data, volatile=True)\n",
        "            output = model(data).data\n",
        "            all_boxes = get_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors)\n",
        "            for i in range(output.size(0)):\n",
        "                boxes = all_boxes[i]\n",
        "                boxes = nms(boxes, nms_thresh)\n",
        "                truths = target[i].view(-1, 5)\n",
        "                num_gts = truths_length(truths)\n",
        "        \n",
        "                total = total + num_gts\n",
        "        \n",
        "                for i in range(len(boxes)):\n",
        "                    if boxes[i][4] > conf_thresh:\n",
        "                        proposals = proposals+1\n",
        "\n",
        "                for i in range(num_gts):\n",
        "                    box_gt = [truths[i][1], truths[i][2], truths[i][3], truths[i][4], 1.0, 1.0, truths[i][0]]\n",
        "                    best_iou = 0\n",
        "                    best_j = -1\n",
        "                    for j in range(len(boxes)):\n",
        "                        iou = bbox_iou(box_gt, boxes[j], x1y1x2y2=False)\n",
        "                        if iou > best_iou:\n",
        "                            best_j = j\n",
        "                            best_iou = iou\n",
        "                    if best_iou > iou_thresh and boxes[best_j][6] == box_gt[6]:\n",
        "                        correct = correct+1\n",
        "        \n",
        "        precision = 1.0*correct/(proposals+eps)\n",
        "        recall = 1.0*correct/(total+eps)\n",
        "        fscore = 2.0*precision*recall/(precision+recall+eps)\n",
        "        logging(\"precision: %f, recall: %f, fscore: %f\" % (precision, recall, fscore))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## --------------------------------------- YOLOV1 --------------------------------------- ##\n",
        "\n",
        "class YOLOv1Train():\n",
        "\t\n",
        "    def __init__(self):\n",
        "        self.model       = ''\n",
        "        self.optimizer   = ''\n",
        "\n",
        "    def train(self, model, criterion, optimizer\n",
        "\t\t\t\t, DataLoaderTrain, DataLoaderTest\n",
        "\t\t\t\t, LEARNING_RATE, EPOCHS, BATCH_SIZE\n",
        "\t\t\t\t, USE_GPU, LOGGER\n",
        "                , CHKP_LOAD, CHKP_DIR, CHKP_NAME, CHKP_EPOCHS\n",
        "                , DEBUG):\n",
        "\n",
        "        if USE_GPU:\n",
        "            model.cuda ()\n",
        "\t\t\n",
        "\t\t# different learning rate\n",
        "        params      = []\n",
        "        params_dict = dict(model.named_parameters())\n",
        "        for key,value in params_dict.items():\n",
        "            if key.startswith('features'):\n",
        "                params += [{'params':[value],'lr':LEARNING_RATE*1}]\n",
        "            else:\n",
        "                params += [{'params':[value],'lr':LEARNING_RATE}]\n",
        "        \n",
        "        if (optimizer == 'SGD'):\n",
        "            optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
        "        \n",
        "        print ('')\n",
        "        epoch_start = 0\n",
        "        if (CHKP_LOAD):\n",
        "            path_model = os.path.join(CHKP_DIR, CHKP_NAME)\n",
        "            if os.path.exists(path_model):\n",
        "                print ('  -- [TRAIN] Loading Chkpoint : ', path_model)\n",
        "                checkpoint  = torch.load(path_model)\n",
        "                epoch_start = checkpoint['epoch']\n",
        "                print ('  -- [TRAIN] Start Epoch : ', epoch_start)\n",
        "                print ('  -- [TRAIN][Loss] Train : ', checkpoint['loss_train'])\n",
        "                print ('  -- [TRAIN][Loss] Val   : ', checkpoint['loss_val'])\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                print ('')\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(epoch_start,EPOCHS):\n",
        "            print ('')\n",
        "            print (' --------------------------------------------------------- ')\n",
        "            if epoch >= 30:\n",
        "                LEARNING_RATE = 0.0001\n",
        "            if epoch >= 40:\n",
        "                LEARNING_RATE = 0.00001\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = LEARNING_RATE\n",
        "            \n",
        "            print ('  -- [TRAIN] Epoch % d / % d '  % (epoch +  1 , EPOCHS))\n",
        "            print ('  -- [TRAIN] LR : {}'.format(LEARNING_RATE))\n",
        "\n",
        "            \n",
        "            ## ----------------------- TRAIN ------------------------\n",
        "            train_loss_total       = 0.0\n",
        "            train_loss_loc_total   = 0.0\n",
        "            train_loss_class_total = 0.0\n",
        "            with tqdm.tqdm_notebook(total = len(DataLoaderTrain)*BATCH_SIZE) as pbar:\n",
        "                for i,(images,target) in enumerate(DataLoaderTrain):\n",
        "                    pbar.update(BATCH_SIZE)\n",
        "                    images = Variable(images)\n",
        "                    target = Variable(target)\n",
        "                    if USE_GPU:\n",
        "                        images,target = images.cuda(),target.cuda()\n",
        "                    \n",
        "                    pred                           = model(images)\n",
        "                    loss_tot, loss_loc, loss_class = criterion(pred,target)\n",
        "                    train_loss_total               += loss_tot.data\n",
        "                    train_loss_loc_total           += loss_loc.data\n",
        "                    train_loss_class_total\t       += loss_class.data \t\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    loss_tot.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    if (DEBUG):\n",
        "                        break\n",
        "                \n",
        "                train_loss_total       /= len(DataLoaderTrain)\n",
        "                train_loss_loc_total   /= len(DataLoaderTrain)\n",
        "                train_loss_class_total /= len(DataLoaderTrain)\n",
        "                if LOGGER != '':\n",
        "                    LOGGER.save_value('Total Loss', 'Train Loss', epoch, train_loss_total)\n",
        "                    LOGGER.save_value('Location Loss', 'Train Loc Loss', epoch, train_loss_loc_total)\n",
        "                    LOGGER.save_value('Class Loss', 'Train Class Loss', epoch, train_loss_class_total)\n",
        "                print ('  -- [TRAIN] Train Loss : ', train_loss_total)\n",
        "\n",
        "            \n",
        "            ## ----------------------- VALIDATION ------------------------\n",
        "            val_loss_total       = 0.0\n",
        "            val_loss_loc_total   = 0.0\n",
        "            val_loss_class_total = 0.0\n",
        "            model.eval() # to set dropout and batch normalization layers to evaluation mode \n",
        "            with torch.no_grad():\n",
        "                with tqdm.tqdm_notebook(total = len(DataLoaderTest)*BATCH_SIZE) as pbar:\n",
        "                    for i,(images,target) in enumerate(DataLoaderTest):\n",
        "                        pbar.update(BATCH_SIZE)\n",
        "                        images = Variable(images)\n",
        "                        target = Variable(target)\n",
        "                        if USE_GPU:\n",
        "                            images,target = images.cuda(),target.cuda()\n",
        "\n",
        "                        pred                           = model(images)\n",
        "                        loss_tot, loss_loc, loss_class = criterion(pred,target)\n",
        "                        val_loss_total               += loss_tot.data\n",
        "                        val_loss_loc_total           += loss_loc.data\n",
        "                        val_loss_class_total\t     += loss_class.data \t\n",
        "\n",
        "                        if (DEBUG):\n",
        "                            break\n",
        "\n",
        "                    val_loss_total       /= len(DataLoaderTrain)\n",
        "                    val_loss_loc_total   /= len(DataLoaderTrain)\n",
        "                    val_loss_class_total /= len(DataLoaderTrain)\n",
        "                    if LOGGER != '':\n",
        "                        LOGGER.save_value('Total Loss', 'Val Loss', epoch, val_loss_total)\n",
        "                        LOGGER.save_value('Location Loss', 'Val Loc Loss', epoch, val_loss_loc_total)\n",
        "                        LOGGER.save_value('Class Loss', 'Val Class Loss', epoch, val_loss_class_total)\n",
        "                    print ('  -- [TRAIN] Validation Loss : ', val_loss_total)\n",
        "\n",
        "            if USE_GPU:\n",
        "                print ('  -- [TRAIN] GPU Memory : ', torch.cuda.max_memory_allocated(device=None)/1024/1024/1024, ' GB')\n",
        "                torch.cuda.reset_max_memory_allocated(device=None)\n",
        "\n",
        "            ## ----------------------- SAVING ------------------------ \n",
        "            if (epoch+1) % CHKP_EPOCHS == 0:\n",
        "                if not os.path.exists(CHKP_DIR):\n",
        "                    os.mkdir(CHKP_DIR)\n",
        "\n",
        "                CHKP_NAME_ = str(CHKP_NAME)\n",
        "                CHKP_NAME_ = CHKP_NAME_.split('_')[0] + '_epoch%.3d.pkl' % (epoch+1)\n",
        "                torch.save({\n",
        "                    'epoch'                : epoch + 1,\n",
        "                    'model_state_dict'     : model.state_dict(),\n",
        "                    'optimizer_state_dict' : optimizer.state_dict(),\n",
        "                    'loss_train'           : train_loss_total,\n",
        "                    'loss_val'             : val_loss_total\n",
        "                        }, os.path.join(CHKP_DIR, CHKP_NAME_)\n",
        "                    )\n",
        "                        \n",
        "\n",
        "        if LOGGER != '' : LOGGER.close()\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class YOLOv1Loss(nn.Module):\n",
        "\n",
        "    def __init__(self,S,B,l_coord,l_noobj):\n",
        "        super(YOLOv1Loss,self).__init__()\n",
        "        self.S = S\n",
        "        self.B = B\n",
        "        self.l_coord = l_coord # for BBox coord loss\n",
        "        self.l_noobj = l_noobj # for BBox confidence vals\n",
        "        \n",
        "        if (0):\n",
        "            print ('  - [yoloLoss] S : ', self.S)\n",
        "            print ('  - [yoloLoss] B : ', self.B)\n",
        "            print ('  - [yoloLoss] l_coord : ', self.l_coord)\n",
        "            print ('  - [yoloLoss] l_noobj : ', self.l_noobj)\n",
        "\n",
        "    def compute_iou(self, box1, box2):\n",
        "        '''Compute the intersection over union of two set of boxes, each box is [x1,y1,x2,y2].\n",
        "        Args:\n",
        "          box1: (tensor) bounding boxes, sized [N,4].\n",
        "          box2: (tensor) bounding boxes, sized [M,4].\n",
        "        Return:\n",
        "          (tensor) iou, sized [N,M].\n",
        "        '''\n",
        "        N = box1.size(0)\n",
        "        M = box2.size(0)\n",
        "\n",
        "        lt = torch.max(\n",
        "            box1[:,:2].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
        "            box2[:,:2].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
        "        )\n",
        "\n",
        "        rb = torch.min(\n",
        "            box1[:,2:].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
        "            box2[:,2:].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
        "        )\n",
        "\n",
        "        wh = rb - lt  # [N,M,2]\n",
        "        wh[wh<0] = 0  # clip at 0\n",
        "        inter = wh[:,:,0] * wh[:,:,1]  # [N,M]\n",
        "\n",
        "        area1 = (box1[:,2]-box1[:,0]) * (box1[:,3]-box1[:,1])  # [N,]\n",
        "        area2 = (box2[:,2]-box2[:,0]) * (box2[:,3]-box2[:,1])  # [M,]\n",
        "        area1 = area1.unsqueeze(1).expand_as(inter)  # [N,] -> [N,1] -> [N,M]\n",
        "        area2 = area2.unsqueeze(0).expand_as(inter)  # [M,] -> [1,M] -> [N,M]\n",
        "\n",
        "        iou = inter / (area1 + area2 - inter)\n",
        "        return iou\n",
        "    \n",
        "    def forward(self,pred_tensor,target_tensor):\n",
        "        verbose = 0\n",
        "        '''\n",
        "        pred_tensor   : (tensor) size(batchsize, S, S, Bx5+20=30) [x,y,w,h,c]\n",
        "        target_tensor : (tensor) size(batchsize, S, S, 30)\n",
        "        '''\n",
        "        if (1): # get masks for BBoxes in the image\n",
        "            N        = pred_tensor.size()[0] #batch_size\n",
        "            coo_mask = target_tensor[:,:,:,4] > 0\n",
        "            noo_mask = target_tensor[:,:,:,4] == 0\n",
        "            if (verbose):\n",
        "                print (' - N : ', N)\n",
        "                print (' - coo_mask : ', coo_mask.shape)\n",
        "                print (' - noo_mask : ', noo_mask.shape)\n",
        "                print (' - coo_mask : ', coo_mask)\n",
        "                print (' - noo_mask : ', noo_mask)\n",
        "\n",
        "            coo_mask = coo_mask.unsqueeze(-1).expand_as(target_tensor)\n",
        "            noo_mask = noo_mask.unsqueeze(-1).expand_as(target_tensor)\n",
        "        \n",
        "        if (1):\n",
        "            coo_target   = target_tensor[coo_mask].view(-1,30)\n",
        "            box_target   = coo_target[:,:10].contiguous().view(-1,5)\n",
        "            class_target = coo_target[:,10:]\n",
        "            \n",
        "            coo_pred   = pred_tensor[coo_mask].view(-1,30)\n",
        "            box_pred   = coo_pred[:,:10].contiguous().view(-1,5) # box[x1,y1,w1,h1,c1]\n",
        "            class_pred = coo_pred[:,10:]                         #    [x2,y2,w2,h2,c2]\n",
        "            if (verbose):\n",
        "                print (' - box_target   : ', box_target.shape)\n",
        "                print (' - box_target   : ', box_target)\n",
        "                print (' - class_target : ', class_target)\n",
        "                print (' - box_pred : ', box_pred.shape)\n",
        "                print (' - box_pred : ', box_pred)\n",
        "                print (' - class_pred : ', class_pred)\n",
        "           \n",
        "        if (1):\n",
        "            # compute not contain obj loss\n",
        "            noo_pred           = pred_tensor[noo_mask].view(-1,30)\n",
        "            noo_target         = target_tensor[noo_mask].view(-1,30)\n",
        "            noo_pred_mask      = torch.cuda.ByteTensor(noo_pred.size())\n",
        "            noo_pred_mask.zero_()\n",
        "            noo_pred_mask[:,4] = 1;\n",
        "            noo_pred_mask[:,9] = 1\n",
        "            noo_pred_c         = noo_pred[noo_pred_mask] #noo pred只需要计算 c 的损失 size[-1,2]\n",
        "            noo_target_c       = noo_target[noo_pred_mask]\n",
        "            nooobj_loss        = F.mse_loss(noo_pred_c,noo_target_c,size_average=False)\n",
        "\n",
        "        if (1):\n",
        "            #compute contain obj loss\n",
        "            \n",
        "            coo_response_mask     = torch.cuda.ByteTensor(box_target.size())\n",
        "            if (verbose):\n",
        "                print (' - box_target : ', box_target)\n",
        "                print (' -- coo_response_mask : ', coo_response_mask.shape)\n",
        "                print (' -- coo_response_mask : ', coo_response_mask)\n",
        "            coo_response_mask.zero_()\n",
        "            if verbose:\n",
        "                print (' -- coo_response_mask : ', coo_response_mask)\n",
        "            coo_not_response_mask = torch.cuda.ByteTensor(box_target.size())\n",
        "            coo_not_response_mask.zero_()\n",
        "            box_target_iou        = torch.zeros(box_target.size()).cuda()\n",
        "            # print (' - box_target_iou : ', box_target_iou)\n",
        "            \n",
        "            \n",
        "        for i in range(0,box_target.size()[0],2): #choose the best iou box\n",
        "            box1             = box_pred[i:i+2]\n",
        "            box1_xyxy        = Variable(torch.FloatTensor(box1.size()))\n",
        "            box1_xyxy[:,:2]  = box1[:,:2]/14. -0.5*box1[:,2:4]\n",
        "            box1_xyxy[:,2:4] = box1[:,:2]/14. +0.5*box1[:,2:4]\n",
        "            \n",
        "            box2             = box_target[i].view(-1,5)\n",
        "            box2_xyxy        = Variable(torch.FloatTensor(box2.size()))\n",
        "            box2_xyxy[:,:2]  = box2[:,:2]/14. -0.5*box2[:,2:4]\n",
        "            box2_xyxy[:,2:4] = box2[:,:2]/14. +0.5*box2[:,2:4]\n",
        "            \n",
        "            if (verbose):\n",
        "                print (' - box1_xyxy[:,:4] : ', box1_xyxy[:,:4])\n",
        "                print (' - box2_xyxy[:,:4] : ', box2_xyxy[:,:4])\n",
        "            \n",
        "            iou               = self.compute_iou(box1_xyxy[:,:4],box2_xyxy[:,:4]) #[2,1]\n",
        "            max_iou,max_index = iou.max(0)\n",
        "            max_index         = max_index.data.cuda()\n",
        "            \n",
        "            coo_response_mask[i+max_index]       = 1\n",
        "            coo_not_response_mask[i+1-max_index] = 1\n",
        "\n",
        "            #####\n",
        "            # we want the confidence score to equal the\n",
        "            # intersection over union (IOU) between the predicted box\n",
        "            # and the ground truth\n",
        "            #####\n",
        "            box_target_iou[i+max_index, torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
        "            \n",
        "            \n",
        "        \n",
        "        box_target_iou = Variable(box_target_iou).cuda()\n",
        "        # print (' - box_target_iou : ', box_target_iou)\n",
        "        # import sys; sys.exit(1)\n",
        "        \n",
        "        # 1.response loss (xpred,ypred vs xtrue,ytrue) + (wpred,hpred vs wpred,hpred)\n",
        "        box_pred_response       = box_pred[coo_response_mask].view(-1,5)\n",
        "        box_target_response_iou = box_target_iou[coo_response_mask].view(-1,5)\n",
        "        box_target_response     = box_target[coo_response_mask].view(-1,5)\n",
        "        loc_loss                = F.mse_loss(box_pred_response[:,:2],box_target_response[:,:2],size_average=False) + F.mse_loss(torch.sqrt(box_pred_response[:,2:4]),torch.sqrt(box_target_response[:,2:4]),size_average=False)\n",
        "        contain_loss            = F.mse_loss(box_pred_response[:,4],box_target_response_iou[:,4],size_average=False)\n",
        "\n",
        "        # 2.not response loss\n",
        "        box_pred_not_response        = box_pred[coo_not_response_mask].view(-1,5)\n",
        "        box_target_not_response      = box_target[coo_not_response_mask].view(-1,5)\n",
        "        box_target_not_response[:,4] = 0\n",
        "        not_contain_loss             = F.mse_loss(box_pred_not_response[:,4], box_target_not_response[:,4],size_average=False)\n",
        "\n",
        "        #3.class loss\n",
        "        class_loss = F.mse_loss(class_pred,class_target,size_average=False)\n",
        "        \n",
        "\n",
        "        total_loss = (self.l_coord*loc_loss + 2*contain_loss + not_contain_loss + self.l_noobj*nooobj_loss + class_loss)/N\n",
        "        return total_loss, self.l_coord*loc_loss, class_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72h-COiKN1s-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "outputId": "16600db5-9cb1-4f38-adf3-6f23068a4040"
      },
      "source": [
        "# get the yolov2 training work\n",
        "\n",
        "datacfg = \"pytorch-yolo2/cfg/voc.data\"\n",
        "cfgfile = \"CS4180-DL/data/cfg/github_pjreddie/yolov2-voc.cfg\"\n",
        "weightfile = \"yolov2-voc.weights\"\n",
        "\n",
        "trainObj = YOLOv2Train()\n",
        "trainObj.train(datacfg, cfgfile, weightfile)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer     filters    size              input                output\n",
            "    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32\n",
            "    1 max          2 x 2 / 2   416 x 416 x  32   ->   208 x 208 x  32\n",
            "    2 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64\n",
            "    3 max          2 x 2 / 2   208 x 208 x  64   ->   104 x 104 x  64\n",
            "    4 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\n",
            "    5 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64\n",
            "    6 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\n",
            "    7 max          2 x 2 / 2   104 x 104 x 128   ->    52 x  52 x 128\n",
            "    8 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
            "    9 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n",
            "   10 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n",
            "   11 max          2 x 2 / 2    52 x  52 x 256   ->    26 x  26 x 256\n",
            "   12 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
            "   13 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
            "   14 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
            "   15 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n",
            "   16 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n",
            "   17 max          2 x 2 / 2    26 x  26 x 512   ->    13 x  13 x 512\n",
            "   18 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
            "   19 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
            "   20 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
            "   21 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n",
            "   22 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n",
            "   23 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024\n",
            "   24 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024\n",
            "   25 route  16\n",
            "   26 conv     64  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x  64\n",
            "   27 reorg              / 2    26 x  26 x  64   ->    13 x  13 x 256\n",
            "   28 route  27 24\n",
            "   29 conv   1024  3 x 3 / 1    13 x  13 x1280   ->    13 x  13 x1024\n",
            "   30 conv    125  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 125\n",
            "   31 detection\n",
            "2019-05-25 15:28:30 epoch 0, processed 0 samples, lr 0.001000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-719b3ce8927e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOv2Train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatacfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfgfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-502d6ae1424b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, datacfg, cfgfile, weightfile)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mt6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mregion_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0mt7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5ccb2ba9f043>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, target)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0manchor_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0manchor_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mpred_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrid_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mpred_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrid_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mpred_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0manchor_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (13) must match the size of tensor b (845) at non-singleton dimension 3"
          ]
        }
      ]
    }
  ]
}